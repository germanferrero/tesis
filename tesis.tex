\documentclass[12pt, a4paper, openany, fleqn]{book}
\usepackage{amsmath, amssymb,}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{relsize}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{xcolor}
\usepackage{dafny}
\usepackage{spverbatim}
\usepackage{tikz}
\usepackage{pst-poker}
\usepackage{tcolorbox}

\tcbuselibrary{breakable}

\newtcolorbox{warningbox}[1]{colback=orange!5!white,colframe=orange!90!black,fonttitle=\bfseries,title=#1}

\newtcolorbox{whitebox}{
    colback=white,
    colframe=white, % Frame color
    arc=0pt,        % No rounded corners
    leftrule=1mm,   % Thickness of the left rule
    rightrule=0pt,  % No right rule
    toprule=0pt,    % No top rule
    bottomrule=0pt, % No bottom rule
    boxsep=0pt,     % Space between text and box
    left=4pt,       % Space between left rule and text
    right=0pt,       % Space between left rule and text
    top=0pt,        % Space between top rule and text
    bottom=0pt,      % Space between bottom rule and text
    beforeafter skip=0pt,
    breakable
}

\newtcolorbox{greenbox}{
    colback=white,
    colframe=green, % Frame color
    arc=0pt,        % No rounded corners
    leftrule=1mm,   % Thickness of the left rule
    rightrule=0pt,  % No right rule
    toprule=0pt,    % No top rule
    bottomrule=0pt, % No bottom rule
    boxsep=0pt,     % Space between text and box
    left=4pt,       % Space between left rule and text
    right=0pt,       % Space between left rule and text
    top=0pt,        % Space between top rule and text
    bottom=0pt,      % Space between bottom rule and text
    beforeafter skip=0pt,
    breakable
}

\newtcolorbox{redbox}{
    colback=white,
    colframe=red, % Frame color
    arc=0pt,        % No rounded corners
    leftrule=1mm,   % Thickness of the left rule
    rightrule=0pt,  % No right rule
    toprule=0pt,    % No top rule
    bottomrule=0pt, % No bottom rule
    boxsep=0pt,     % Space between text and box
    left=4pt,       % Space between left rule and text
    right=0pt,       % Space between left rule and text
    top=0pt,        % Space between top rule and text
    bottom=0pt,      % Space between bottom rule and text
    beforeafter skip=0pt,
    breakable
}

\newif\ifUsePstPoker
\UsePstPokerfalse

\newcommand{\disgrecion}[1]{#1}
\newcommand{\declConst}[2]{\text{const } #1 : #2}
\newcommand{\declVar}[2]{\text{var } #1 : #2}
\newcommand{\wip}[1]{\begin{center} [WIP]#1[END WIP] \end{center}}
\renewcommand{\lstlistingname}{Dafny}

\newcounter{example}[chapter]
\renewcommand{\theexample}{\thechapter.\arabic{example}}

% Command to create an example with the desired format
\newcommand{\example}[1]{
  \refstepcounter{example} % Increment the example counter
  \vspace{1em}
  \noindent\textbf{Ejemplo \theexample: #1}
}

\newcommand{\hoare}[3]{\ensuremath{[#1]\ #2\ [#3]}}
\newcommand{\hoareTheorem}[3]{\ensuremath{\vdash[#1]\ #2\ [#3]}}
\newcommand{\verticalHoare}[3]{
    \begin{align*}
        [#1]
        #2
        [#3]
    \end{align*}
}

\newcommand{\inferenceRule}[2]{
    \begin{equation*}
        \frac{#1}{#2}
    \end{equation*}
}

\linespread{1.1}
\author{Germán Ferrero}
\title{Construcción formal de programas asistida por Dafny}
\begin{document}
    \chapter{Introducción}
    El objetivo de esta tesis es analizar el potencial que tiene Dafny como herramienta de apoyo para la materia Algoritmos y Estructuras de Datos I, de nuestra Lic. en Cs. de la Computación.

    Esta materia culmina un proceso de formación en métodos formales para la especificación, comprobación y derivación de programas que se inicia con el estudio de lógica proposicional en la materia pre-correlativa Introducción a los Algoritmos y se expande hacia la definición de un lenguaje imperativo minimal cuya semántica es definida en términos de transformación de predicados.
    En el transcurso, los estudiantes transitan un camino riguroso en el cual aprenden a operar un sistema formal con su alfabeto, expresiones, axiomas y reglas de inferencia, para luego demostrar teoremas dentro del mismo. Este sistema se complejiza paulatinamente con la introducción de predicados y expresiones cuantificadas, hasta el punto en que puede ser utilizado para especificar programas imperativos, en cuanto que la precondición y poscondición de estos programas se expresan como predicados válidos del sistema formal y la semántica de cada una de las sentencias del lenguaje está también definida en base a fórmulas de este sistema.

    Se busca así que los estudiantes conciban un entendimiento profundo de los programas como objetos formales de estudio que deben ser precisamente especificados y cuya implementación puede (o mejor: debe) ser demostrada dentro de un sistema formal para garantizar su correctitud.

    Las materias resaltan el valor adicional que se obtiene al especificar y verificar formalmente los programas en comparación con especificarlos vagamente o probar su correctitud solo para algunos casos específicos mediante la práctica usual de \textit{testing} de software.

    Consideramos esta enseñanza de la programación a través de métodos formales de altísimo valor, y buscamos con este trabajo potenciarla.

    Durante el cursado de estas materias, y particularmente en Algoritmos y Estructuras de Datos I, los estudiantes destinan gran parte del tiempo de cursada y práctica fuera del claustro a la formulación de demostraciones dentro del sistema formal aprendido. Un alto porcentaje de los ejercicios de los prácticos de la materia conllevan la demostración de teoremas y es también un condimento central a la hora de las evaluaciones.

    Demostrar teoremas requiere de un entrenamiento meticuloso en la manipulación simbólica, capacidad de abstracción y ejercitación en la búsqueda de patrones para encontrar posibles aplicaciones de los axiomas y reglas de inferencia del sistema formal en cada uno de los pasos de la demostración.
    Esta es una actividad que si bien refuerza nuestro entendimiento de cómo se opera un sistema formal y por qué podemos confiar en él, a menudo satura nuestra capacidad cognitiva, dejando poco espacio para el aprendizaje de otros aspectos, o en otros planos, del tema que estamos estudiando.

    Un escenario que nos despierta particular interés es el de la puesta en práctica de la manipulación simbólica de la especificación de un programa como metodología para \textit{derivar} su implementación. Mediante esta técnica el programa se construye al mismo tiempo en que se construye la demostración de su correctitud.
    Esta práctica es tal vez uno de los justificantes del intenso entrenamiento en la operatoria del sistema formal. Justificante en cuanto que resaltamos las bondades de la derivación de programas a partir de sus especificación como método para conseguir implementar los programas.

    Nuestra hipótesis de trabajo es que el énfasis actual puesto en la operatoria del sistema formal es tal vez excesivo y contraproducente.

    Demostrar programas (en el caso de la programación imperativa), implica una comprensión profunda de conceptos fundamentales como tipos de datos, estado y transformación de estado, precondición, poscondición, invariante de un ciclo, función de cota, etc. Incluso también comprender la confianza que depositamos en los axiomas y las reglas de inferencia en cuanto a sus consistencia.
    A la vez, hacerlo con lápiz y papel acarrea un trabajo meticuloso para hilvanar axiomas y reglas de inferencia en la construcción de la demostración, como mencionamos anteriormente.

    Desde nuestra mirada, ambas cosas son importantes, pero lo primero es primordial y lo segundo es complementario. Debemos priorizar el entendimiento profundo de los conceptos fundamentales sin dejar de entender el valor de las pruebas enmarcadas en un sistema formal y la necesidad de construirlas, pero manteniendo el foco en lo primero.

    En la actualidad existen numerosas herramientas de verificación formal de software en las que podemos delegar, en parte, la construcción de pruebas. Estas herramientas nos permiten aprender los conceptos fundamentales, a la vez que resuelven por nosotros el trabajo tedioso, liberando nuestra capacidad cognitiva para dar sentido a los programas que desarrollamos y de las piezas fundamentales que posibilitan su verificación.

    Creemos que en el afán de enseñar las bondades de la derivación formal, propiciamos a menudo el naufragio de muchas y muchos de nosotros que perfectamente hubiéramos podido llegar a construir los mismos programas, mediante otras técnicas, que aprovechen mejor nuestro conocimiento previo, y favorezcan la construcción de sentido sobre los programas que desarrollamos. Técnicas que no necesariamente se basan en la manipulación simbólica, sino en un rango más abierto de posibilidades, como la creatividad y el ingenio en todas sus expresiones, la analogía con otros saberes o la capacidad de resolución de problemas de forma procedural en otros ámbitos de la vida cotidiana puesta al servicio de la escritura de programas. En \cite{Losano}, Leticia Losano analiza las dificultades que atraviesan los estudiantes durante el cursado de Introducción a los Algoritmos, en particular en cuanto a la formulación de demostraciones. Su trabajo nos convoca y motiva en la búsqueda de alternativas. Sostenemos además, que estas técnicas alternativas podrían combinarse con la derivación formal en un mismo proceso de desarrollo.

    Finalmente consideramos que, en el primer año de la carrera durante el cual se desarrollan estas materias, delegar parte de la generación de pruebas en las herramientas de verificación de software que tenemos hoy a nuestro alcance puede resultar en que formemos a más estudiantes capaces de obtener software verificado al final del día. Estudiantes que desarrollen un sentido más profundo de los conceptos fundamentales y los pongan en práctica a lo largo del resto de la carrera. E incluso, en un estadio más avanzado de la misma y con otro entendimiento del valor que supone, estén en mejores condiciones para profundizar su conocimiento en sistemas formales.

    \chapter{Programación formal asistida por Dafny}

    En este capítulo presentamos brevemente los conceptos de programación formal que creemos resultan necesarios a la hora de escribir programas imperativos en Dafny.

    \section{Condiciones de contexto para la propuesta}
    Visualizamos un estudiantado que ya cuente con una primera experiencia en algún lenguaje de programación imperativa en la cual se hayan familiarizado de manera práctica con los conceptos básicos: tipos de datos, expresiones, precedencia de operadores, árbol de tipado e incluso con la mecánica de los comandos típicos del paradigma: la asignación, la alternativa (\textit{if-else}), y el de ciclo (\textit{while/for}). Esperaríamos como resultado de esta experiencia que los estudiantes comprendan el control de flujo de un programa imperativo, identifiquen cuándo resulta conveniente utilizar un \textit{if} o un \textit{while}, y hayan escrito baterías de tests no exhaustivas para sus programas.

    A continuación, ubicamos una segunda instancia formativa, de carácter formal, que ofrezca a los estudiantes la posibilidad de profundizar su entendimiento de los programas como objetos formales cuya correctitud puede ser demostrada.
    En esta segunda instancia los estudiantes razonan sobre los programas, ya no en un plano mecánico, operativo, sino en el plano semántico, a partir de las definiciones de Hoare.

    En lo que resta de este capítulo repasamos estas definiciones con foco en aquellas que nos provean los elementos necesarios para desarrollar software verificado en Dafny.

    \section{Especificación de un programa}
    La primera pregunta que surge al analizar un programa es tal vez: ¿El programa hace lo que tiene que hacer? Para poder responder esta pregunta primero debemos ser capaces de definir qué debe hacer el programa. Para ello es conveniente contar con un lenguaje suficientemente expresivo y preciso en el cual expresar tal definición. Expresivo en cuanto a que el mismo lenguaje nos permita definir qué hacen distintos tipos de programas, y preciso en cuanto a que la definición no de lugar a ambigüedades.
    A esta tarea la llamamos \textit{especificar} un programa.

    Una forma de especificar qué hace un programa es definiendo condiciones que cumplirán ciertas variables luego de la ejecución del programa. Esta idea da lugar a la siguiente definición de qué es un programa, al menos en cuanto a cómo se relaciona con las variables y constantes a las que tiene acceso.

    En programación imperativa, un programa es un transformador de estados. Un estado es una valuación de las variables y constantes a las que un programa tendrá acceso, y ejecutar el programa, significará una transformación de ese estado inicial, en otro estado final.

    Utilizaremos condiciones sobre las variables y constantes para describir el estado final.
    El lenguaje para expresar estas condiciones será el de la lógica matemática con sus operadores lógicos ($\land$, $\lor$, $\Rightarrow$, $\neg$) y cuantificadores ($\forall$, $\exists$) aplicados a las variables y constantes del programa o a expresiones construídas a partir de ellas. (ej: $X = q * Y + r \land 0 \leqslant r < y$).

    Notar que si preservamos en constantes (que diferenciamos mediante letras mayúsculas) los valores de entrada de interés, luego en las condiciones sobre el estado final podemos expresar la relación que deben guardar los valores de salida de interés respecto a los de entrada.

    Este mismo lenguaje nos permite especificar condiciones que deben cumplirse en el estado inicial para que se considere válido ejecutar el programa. (ej: $X > 0 \land Y > 0$)

    Utilizamos la ``Terna de Hoare'', \hoare{P}{S}{Q} para especificar programas donde $P$ es una precondición, $S$ un programa y $Q$ una poscondición, y la interpretamos así:

    ``Cada vez que se ejecuta $S$ a partir de un estado que satisface $P$, el programa termina en un estado que satisface $Q$''

    \example{Especificación de la división entera}

    Un programa $S$ que ejecute la división entera de dos números enteros positivos $X$ e $Y$, puede ser especificado con la siguiente terna:
    \verticalHoare{X > 0 \land Y > 0}{S}{X = q * Y + r \land 0 \leqslant r < Y}
    Donde $X$ e $Y$ serán constantes y $q$ y $r$ variables, todas de tipo entero.
    Notar que la precondición impide la división por $0$ y que $q$ y $r$ tomarán respectivamente los valores del cociente y resto de la división de $X$ por $Y$ luego de ejecutar $S$.

    \vspace{1em}

    Escribir la especificación de un programa antes de pasar a implementarlo es (o debiera ser) una práctica ineludible, ya que hacerlo nos reasegura que entendemos qué es lo que debemos implementar.
    Al especificar un programa logramos también separar conceptualmente dos aspectos independientes del mismo: su especificación (qué hace), y su implementación (cómo lo hace).
    Gracias a la precisión del lenguaje utilizado para especificar, quienes quieran saber qué hace el programa solo necesitarán leer y entender su especificación, sin necesidad de revisar su implementación para descubrirlo. Esto es una gran ventaja, ya que la especificación de un programa suele ser más concisa que su implementación.

    Ahora que contamos con un lenguaje preciso para describir qué debe hacer un programa, queda responder cómo hacemos para garantizar que efectivamente lo hace.

    \section{Prueba de correctitud}
    Con ``programación formal'' nos referimos a garantizar que un programa efectivamente cumple con su especificación mediante la generación de una demostración de correctitud bajo un sistema formal de deducción. Es decir, una secuencia de pasos lógicos que logren deducir la correctitud del programa a partir de un conjunto mínimo de axiomas y reglas de inferencia.

    Si logramos generar una demostración de \hoare{P}{S}{Q} diremos que la terna es un teorema y lo denotaremos \hoareTheorem{P}{S}{Q}.

    Al igual que un teorema matemático, por ejemplo $\vdash x = x + y * 0$, donde la igualdad vale para cualquier valor de $x$ e $y$, un teorema de la forma \hoareTheorem{P}{S}{Q} significa que la terna vale para cualquier estado inicial que satisfaga $P$. Es decir, a diferencia del \textit{testing} de programas que chequea algunos casos particulares no exhaustivos, una demostración formal probará la correctitud del programa para todos los casos posibles. Lo cual incrementa drásticamente la confianza que podemos depositar en los programas.

    Los primeros esfuerzos por definir un sistema formal de deducción para la programación imperativa se condensaron en lo que conocemos como la lógica de Hoare.
    La misma establece axiomas y reglas de inferencia para un lenguaje simple equipado con los comandos esenciales del paradigma imperativo: la asignación, el \textit{if} y el \textit{while}. Repasaremos la lógica de Hoare en seguida con la ayuda de Dafny.

    \section{Herramientas de verificación automática}
    Hilvanar axiomas y reglas de inferencia para lograr una demostración de un programa, incluso de uno simple, es una tarea tediosa. Y es por eso que desde la presentación de la Lógica de Hoare se sostiene un gran esfuerzo de investigación y desarrollo en técnicas de mecanización y automatización de la generación de demostraciones que dio lugar a las herramientas de verificación automática de software con las que contamos actualmente, como Dafny.

    De ellas, debemos esperar que oculten la complejidad de los mecanismos que hilvanan axiomas y reglas de inferencia en milisegundos, y que nos permitan escribir software verificado siempre que entendamos los axiomas y reglas que rigen la automatización que realizan.

    Al esconder dicha complejidad, estas herramientas nos facilitan el acceso a la programación formal permitiéndonos ejercitar la especificación de programas y el uso de un sistema deductivo para demostrar su correctitud, enfocando el esfuerzo cognitivo en el plano semántico en vez del mecánico.

    A continuación haremos un repaso de la Lógica de Hoare al tiempo que pondremos a prueba Dafny, en cuanto a su capacidad para aplicar los axiomas y reglas de inferencia del sistema. Este ejercicio, nos proveerá del conocimiento necesario para escribir programas reales en Dafny en el siguiente capítulo.

    \section{Lógica de Hoare en Dafny}
    La lógica de Hoare está compuesta por un axioma, el axioma de la asignación, y un conjunto de reglas de inferencia. Para presentar las reglas de inferencia utilizaremos la siguiente notación:
    \inferenceRule{\vdash S_1, ..., \vdash S_n}{\vdash S}
    Que indica que la \textit{conclusión} $\vdash S$ puede deducirse a partir de las \textit{hipótesis} $\vdash S_1, ..., \vdash S_n$, las cuales serán o bien todos teoremas de la lógica de Hoare (en la forma $\vdash[P]S[Q]$) o bien una combinación de teoremas de la lógica de Hoare con teoremas de la lógica matemática.

    \subsection{Axioma de la asignación}
    La asignación es el comando que toma la forma $x := E$ donde $x$ es una variable y $E$ es una expresión, que posiblemente contiene la variable $x$, y utilizamos para asignar a $x$ el valor que resulte de evaluar $E$ al momento de la asignación.

    Si denotamos con $P[E/x]$ al predicado que resulta de reemplazar sintácticamente en $P$ todas las ocurrencias de $x$ por $E$, el axioma de la asignación es:

    \begin{center}
        \hoareTheorem{P[E/x]}{x:=E}{P}
    \end{center}

    El axioma nos dice que un predicado con posibles cláusulas sobre $x$ siempre valdrá  luego de asignar $E$ a $x$ si antes de la asignación valía un predicado similar a $P$ pero en donde esas cláusulas referían a $E$ en vez de a $x$.

    Podemos escribir un simple programa en Dafny para probar cómo este resuelve verificaciones que implican conocimiento del axioma de la asignación:

    \example{Axioma de la asignación en Dafny}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        function E(x: int): int
        predicate P(x: int)

        method axioma_de_la_asignacion()
        {
            var x: int := *;
            assume P(E(x));
            x := E(x);
            assert P(x);
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    En dafny una \textit{función} (\inlinedafny{function}) se utiliza para calcular valores a partir de sus parámetros de entrada, no tiene efectos secundarios y puede tener definiciones recursivas. Un \textit{predicado}(\inlinedafny{predicate}) es equivalente a una función cuyo valor de retorno es un booleano. Un \textit{método}(\inlinedafny{method}) podrá tener parámetros de entrada y de retorno, tener efectos secundarios y utilizar en su cuerpo comandos imperativos.

    En el ejemplo definimos una función $E$ sobre una variable de tipo entero $x$ que devuelve a su vez un valor entero.
    Un predicado $P$ sobre una variable de tipo entero.
    Y un método sin parámetros de entrada ni de retorno en donde ponemos a prueba la habilidad de Dafny para utilizar el axioma de la asignación.
    No es obligatorio definir un cuerpo para $E$ y $P$ lo que nos permite en este ejemplo referirnos a una función arbitraria y a un predicado arbitrario.
    En la línea 6 utilizamos \inlinedafny{x := *} para inicializar $x$ a un entero cualquiera.
    En la línea 7 establecemos la hipótesis de que $P$ vale para $E(x)$ haciendo uso del commando \inlinedafny{assume}.
    En la línea 8 realizamos la asignación.
    Y en la línea 9 le exigimos a Dafny probar que $P$ vale para $x$ en ese punto del programa mediante el commando \inlinedafny{assert}.
    Efectivamente Dafny logra verificarlo (lo cual simbolizamos con la línea verde vertical a la izquierda \footnote{El editor de texto Visual Studio Code junto con la extensión de Dafny utiliza una línea verde como esta para denotar las partes del programa que han logrado ser verificadas, cada vez que guardamos el archivo.}), haciendo uso del axioma de la asignación. 
    \vspace{1em}

    \subsection{Regla del fortalecimiento de la precondición}
    Esta regla indica que si tenemos un programa que nos lleva de $P'$ a $Q$ entonces ese mismo programa también nos lleva a $Q$ desde cualquier precondición más fuerte que $P'$.
    \inferenceRule{\hoareTheorem{P'}{S}{Q}\ \ \vdash P \rightarrow P'}{\hoareTheorem{P}{S}{Q}}

    \example{Regla del fortalecimiento de la precondición en Dafny}
    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate P(x: int)
        predicate P'(x: int)
        predicate Q(x: int)

        method S(x: int)
            requires P'(x)
            ensures Q(x)

        method regla_del_fortalecimiento_de_la_precondicion(x: int)
        {
            assume forall x: int :: P(x) ==> P'(x);
            assume P(x);
            S(x);
            assert Q(x); 
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}
    Aquí hemos utilizado las sentencias \inlinedafny{requires} y \inlinedafny{ensures} para especificar la precondición y poscondición respectivamente del programa $S$. Durante el proceso de verificación del segundo método, donde se invoca a $S$, Dafny asumirá que $S$ cumple con su especificación, sin inspeccionar su implementación. Esto resulta muy útil en la práctica para partir el programa en programas más pequeños, lograr primero una implementación verificada del método principal, postergando la implementación de las partes.

    Para verificar el \textit{assert} de la línea 15. Dafny tuvo que aplicar la regla del fortalecimiento de la precondición a partir de la hipótesis de la línea 12 y de la especificación de $S$.

    De este ejemplo y del anterior, podemos notar que aunque en la teoría solemos referirnos con un predicado $P$ a una fórmula sobre el conjunto de las variables del programa, en Dafny debemos especificar sobre cuáles opera específicamente, lo cual naturalmente facilita el trabajo de la herramienta a la hora de verificar.
    \vspace{1em}

    \subsection{Regla del debilitamiento de la poscondición}
    La regla del debilitamiento de la poscondición nos dice que si un programa $S$ nos lleva de $P$ a $Q$, el mismo programa nos lleva de $P$ a cualquier poscondición más débil que $Q$. Podemos ver a Dafny utilizando esta regla con un ejemplo análogo al anterior.
    \inferenceRule{\hoareTheorem{P}{S}{Q'}\ \ \vdash Q' \rightarrow Q}{\hoareTheorem{P}{S}{Q}}

    \example{Regla del debilitamiento de la poscondición en Dafny}
    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate P(x: int)
        predicate Q(x: int)
        predicate Q'(x: int)

        method S(x: int)
            requires P(x)
            ensures Q'(x)

        method test(x: int)
        {
            assume forall x: int :: Q'(x) ==> Q(x);
            assume P(x);
            S(x);
            assert Q(x); 
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    \subsection{Regla de la composición}
    La regla de la composición indica que si un programa $S1$ nos lleva de un predicado $P$ a un predicado $R$, desde el cual otro programa $S2$ nos lleva hasta un predicado $Q$, entonces secuenciar $S2$ luego de $S1$, nos da un programa que nos lleva del predicado $P$ al predicado $Q$.

    \inferenceRule{\hoareTheorem{P}{S_1}{R}\ \ \hoareTheorem{R}{S_2}{Q}}{\hoareTheorem{P}{S_1;S_2}{Q}}

    \example{Regla de la composición en Dafny}

    El siguiente ejemplo ilustra la capacidad de Dafny para aplicar la regla de la composición.

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate P(x: int)
        predicate Q(x: int)
        predicate R(x: int)

        method S1(x: int)
            requires P(x)
            ensures R(x)
        
        method S2(x: int)
            requires R(x)
            ensures Q(x)

        method regla_de_la_composicion(x: int)
        {
            assume P(x);
            S1(x);
            S2(x);
            assert Q(x);
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}
    Con frecuencia resultará útil en la práctica insertar un \textit{assert} de algún predicado $R$ en el algún punto intermedio de nuestro programa cuando intuyamos que la verificación debería lograrse aplicando esta regla. Al hacerlo no solo comprobamos que el verificador puede asegurar ese predicado en ese punto, sino que también lo ayudamos a tenerlo en cuenta (ahora como teorema) para probar lo que sigue.

    \subsection{Regla del \textit{if}}
    Esta regla nos dice que si ambas ramificaciones del \textit{if} junto con la información agregada por la correspondiente valuación de la guarda nos llevan de la precondición a la poscondición, entonces el \textit{if}, como constructo que las compone, también lo hace.

    \inferenceRule{\hoareTheorem{P \land B}{S}{Q}\ \ \hoareTheorem{P \land \lnot B}{T}{Q}}{\hoareTheorem{P}{if\ B\ then\ S\ else\ T}{Q}}

    \example{Regla del \textit{if} en Dafny}

    En este ejemplo Dafny utiliza las especificaciones de los métodos $S$ y $T$ y la regla del \textit{if} para realizar la verificación.

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate P(x: int)
        predicate Q(x: int)
        function B(x: int): bool

        method S(x: int)
            requires P(x) && B(x)
            ensures Q(x)

        method T(x: int)
            requires P(x) && !B(x)
            ensures Q(x)

        method regla_del_if(x: int)
        {
            assume P(x);
            if B(x) {
                S(x);
            } else {
                T(x);
            }
            assert Q(x);
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    En la práctica, para que Dafny pueda utilizar esta regla, debemos asegurarnos de que puede establecer la hipótesis correspondiente a cada rama. Es decir, que si Dafny no está logrando la verificación, debemos inspeccionar cada caso del \textit{if} por separado para ver si la poscondición se cumple al final de su cuerpo.

    \vspace{1em}

    \subsection{El \textit{while}, el invariante y la función de cota}
    El $while$ es la sentencia de la programación imperativa que nos permite escribir programas realmente interesantes, cuya estrategia resolutiva se desenvuelve en uno o más ciclos que computan de manera creativa algún valor deseado. En estos programas los ciclos son típicamente la parte más difícil tanto de elaborar como de verificar.

    Para trabajar con ciclos en términos formales debemos abrazar dos conceptos: el invariante del ciclo y su función de cota.
    El invariante es una condición que se cumple a la entrada del ciclo, a la salida del mismo, y durante cada una de las iteraciones. La función de cota es una expresión numérica que se modifica en cada iteración del ciclo y atestigua que el ciclo termina eventualmente.

    Si nuestro programa incluye un ciclo que realiza algún trabajo interesante, este ciclo tiene un invariante y una función de cota, lo hayamos hecho explícito o no. Utilizamos ciclos para encontrar respuestas o construir soluciones (en definitiva, lograr alguna transformación de estado deseada) de manera iterativa y constructiva. El invariante del ciclo es su propiedad intrínseca que nos dice que efectivamente estamos construyendo, paso a paso, esa transformación. Y la función de cota es la que nos dice que eventualmente concluiremos el trabajo.

    Imaginemos dos personas a las que le pedimos que edifiquen una columna de $2mts$ cada una por separado. Para realizar esa columna se necesitan $N$ bloques de cemento. Una vez que empezaron su tarea, volteamos cada tanto a revisar el progreso y por un lado vemos como una de ellas avanza con su columna bloque a bloque, de abajo hacia arriba, mientras que la otra no parece estar siguiendo ningún patrón de avance identificable. Tenemos la certeza de que la primera terminará la columna por que hay un invariante: a cada momento $t$ la persona ya colocó $t$ bloques, y una función de cota: con cada bloque colocado, falta uno menos para llegar a $N$.

    Enunciar el invariante y la función de cota incluso antes de implementar el cuerpo del ciclo, nos ayuda a dar sentido a la estrategia resolutiva del mismo, aumenta nuestras posibilidades de implementarlo correctamente y es indispensable para construir una demostración de su correctitud.

    Antes de pasar a la regla de inferencia del \textit{while} repasemos el problema de la división entera. Este problema se resuelve con un programa que contiene un ciclo.

    \example{División entera de dos números enteros positivos}

    Queremos obtener un programa que dados dos números enteros positivos $x$ e $y$, compute el cociente $q$ y el resto $r$ de la división entera de $x$ por $y$.
    Recordemos que $q$ y $r$ serán números enteros que cumplen:
    $x = q * y + r \land 0 \leqslant r < y$.
    Ó dicho de otra forma $q$ y $r$ son tales que $x$ se distribuye entre ``$y$ veces $q$'' y un resto $r$ que es menor a $y$.
    Si pensamos el problema como un proceso iterativo en el que debemos repartir la cantidad $x$ entre ``$y$ partes iguales'', podemos decir que al principio no hemos repartido nada aún, y en cada iteración del ciclo repartiremos una unidad a cada una de las partes, mientras alcance para todas. Cuando no alcance para todas, habremos terminado, y tendremos un resto $r$ entre 0 e $y$. En todo momento, lo que aún queda por repartir será el resto $r$, la guarda del ciclo será $r \geqslant y$ (que resulta verdadera si aún alcanza para repartir una unidad a cada una) y lo repartido a cada parte será $q$.

    Antes de entrar al ciclo tendremos $r=x$ y $q=0$ y en todo momento mantendremos como invariante $x = q * y + r \land 0 \leqslant r$, puesto que lo que sacamos de $r$ lo ponemos en $q * y$. Notemos que $r - y$ decrecerá en cada iteración y está acotada por lo bajo, por lo que nos sirve como función de cota que asegura que el ciclo terminará.
    Al final del ciclo valdrá el invariante (por haberlo mantenido a cada paso) y la negación de la guarda (por haber terminado). La conjunción de ambas cosas nos dice que: $x = q * y + r \land 0 \leqslant r < y$. Por tanto $q$ y $r$ serán el cociente y resto de la división entera de $x$ por $y$.

    La implementación en Dafny aún no verificada de nuestro programa luce así:
    \vspace{1em}
    \begin{whitebox}
    \begin{dafny}[gobble=8]
        method division_entera(x: int, y: int) returns (q: int, r: int)
            requires x > 0 && y > 0
    \end{dafny}
    \end{whitebox}

    \begin{redbox}
    \begin{dafny}[gobble=8,firstnumber=3]
            ensures x == q * y + r && 0 <= r < y
        {
    \end{dafny}
    \end{redbox}

    \begin{whitebox}
    \begin{dafny}[gobble=8, firstnumber=5]
            q := 0;
            r := x;
            while r >= y
            {
                q := q + 1;
                r := r - y;
            }
        }
    \end{dafny}
    \end{whitebox}
    \vspace{1em}

    \begin{redbox}
        Error: a postcondition could not be proved on this return path. Could not prove: $x = q * y + r$
    \end{redbox}
    \vspace{1em}

    Para que Dafny pueda verificar esta implementación deberemos \textbf{anotar} el ciclo con un invariante y función de cota apropiados. Ya que, como veremos a continuación, ambos son piezas fundamentales de la regla de inferencia del \textit{while}.

    \vspace{1em}

    \subsection{Regla del \textit{while}}

    La regla de inferencia del \textit{while} es la siguiente:

    \inferenceRule{\hoareTheorem{I \land B \land (E = n)}{S}{I \land (E < n)}\ \ \ \ \vdash I \land B \rightarrow E \geqslant 0}{\hoareTheorem{I}{while\ B\ do\ S}{I \land \lnot B}}

    La primera hipótesis dice que $S$, el cuerpo del while, debe ser tal que si el invariante $I$ y la guarda $B$ se cumplen antes de ejecutar $S$ luego de ejecutar $S$ el invariante continúa valiendo y además la función de cota $E$ se redujo al menos en una unidad.

    La segunda hipótesis dice que el invariante $I$ en conjunción con la guarda $B$ aseguran que la función de cota es mayor o igual a 0. Estableciendo así una cota inferior para una variable que decrece en cada iteración por la hipótesis anterior.

    Si estas dos hipótesis se cumplen, entonces podemos derivar que estableciendo el invariante en la entrada del ciclo, el mismo nos llevará a un estado en el cual se cumple el invariante y la negación de la guarda.

    Dafny, como lo indica la regla, depende fuertemente de que el invariante del ciclo y la función de cota estén definidos para intentar probar su correctitud. Y salvo en casos triviales en los que puede inferirlos por su cuenta\footnote{Para intentar inferir el invariante usará técnicas de aproximación de dominios abstractos que analizan estáticamente el programa para aproximar el rango en el que se mueven sus variables.\cite{10.1007/11804192_17}. Para la función de cota, como ejemplos, en caso de que la guarda sea del tipo $E<F$ probará con $F-E$, y en el caso de que sea $E!=F$ probará con $if\ E<F\ then\ F-E\ else\ E-F$.}, será nuestra tarea proveer el invariante del ciclo para que la verificación pueda realizarse.

    Retomando el ejemplo de la división entera. Podemos lograr una implementación verificada anotando el ciclo con el invariante $x = q * y + r \land 0 \leqslant r$ (utilizando la anotación \inlinedafny{invariant}), y la función de cota $r$ (con la anotación \inlinedafny{decreases}).

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method division_entera(x: int, y: int) returns (q: int, r: int)
            requires x > 0 && y > 0
            ensures x == q * y + r && 0 <= r < y
        {
            q := 0;
            r := x;
            while r >= y
                invariant x == q * y + r && 0 <= r
                decreases r - y
            {
                q := q + 1;
                r := r - y;
            }
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    \subsection{Reglas de conjunción y disyunción}
    Dos reglas más completan el sistema deductivo de la Lógica de Hoare para este lenguaje imperativo simple.

    La regla de conjunción de especificaciones:
    \inferenceRule{\hoareTheorem{P}{S}{Q}\ \ \hoareTheorem{P'}{S}{Q'}}{\hoareTheorem{P \land P'}{S}{Q \land Q'}}

    Y la regla de disyunción de especificaciones:
    \inferenceRule{\hoareTheorem{P}{S}{Q}\ \ \hoareTheorem{P'}{S}{Q'}}{\hoareTheorem{P \lor P'}{S}{Q \lor Q'}}

    \subsection{Recapitulación}
    Hemos visto el axioma de la asignación y las reglas de inferencia de la Lógica de Hoare para un lenguaje imperativo simple y pusimos a prueba la capacidad de Dafny para verificar programas que requieren hacer uso de ellas. Al programar en Dafny, a través de un entorno de desarrollo apropiado, estaremos constantemente interactuando con el verificador en la tarea conjunta de lograr una implementación verificada de nuestros programas. Dafny intentará hacerlo de manera autónoma, resolviendo el tedio de articular axiomas y reglas en pos de una demostración, pero en ocasiones deberemos ayudarlo, entendiendo qué reglas de inferencia son necesarias a cada paso y verificando que las hipótesis para aplicar esas reglas se satisfacen y el verificador está al tanto de ellas. Además, y siendo esto lo más importante, deberemos anotar cada ciclo con invariantes y funciones de cota.

    \chapter{Metodología para escribir programas en Dafny}
    En este capítulo presentamos una metodología para escribir programas en Dafny. La metodología propuesta supone una serie de pasos a seguir que nos resultaron útiles a la hora de ordenar el desarrollo y la interacción con el verificador.
    Introduciremos la metodología a través de un ejemplo concreto: el algoritmo de Euclides para el cálculo del máximo común divisor. Como prólogo de este capítulo, nos gustaría relatar primero la experiencia propia intentando resolver el problema del máximo común divisor antes de ser iluminados con la solución de Euclides.

    \section{¿Qué tan relevante es la derivación de programas? una opinión personal}
    Queremos escribir un programa, verificado, que compute el máximo común divisor entre dos números enteros positivos $m$ y $n$, con $m \geqslant n$. Formalmente, si utilizamos $x \mid y$ para decir que $x$ divide a $y$, definimos el máximo común divisor $mcd$ como:

    \begin{center}
        \begin{math}
            (mcd \mid m) \land (mcd \mid n) \land (\forall d: (d \mid m) \land (d \mid n) : d \leq mcd)
        \end{math}
    \end{center}

    Nuestra primera exploración en la búsqueda de un algoritmo que compute el máximo común divisor entre $m$ y $n$ fue a partir de la factorización en primos de $m$ y $n$. Dada por:

    \begin{center}
        \begin{math}
            m = \prod_{i=0}^{i=M} p_{i}^{m_i}\ , \ \ \ n = \prod_{i=0}^{i=N} p_{i}^{n_i}
        \end{math}
    \end{center}

    donde $p_0=2$, $p_1= 3$, $p_2= 5$, ... y $p_{M}$, $p_{N}$ son los primos más grandes que aparecen en la factorización de $m$ y $n$ respectivamente; y $m_i$, $n_i$ los exponentes del primo $p_i$ en sus respectivas factorizaciones, (siendo $x_i=0$, si $p_i$ no aparece en la factorización).

    Utilizando estas definiciones el m.c.d. entre ellos será:

    \begin{center}
        \begin{math}
            mcd(m, n) = \prod_{i=0}^{i=min(M, N)} p_{i}^{min(m_i, n_i)}
        \end{math}
    \end{center}

    Proponemos como estrategia de resolución, empezar con la peor solución $mcd' = 1$ e iterar sobre los números primos ($p_0$, $p_1$, ..., $p_{min(M, N)}$) multiplicando $mcd'$ por $p_{i}^{min(m_{i}, n_{i})}$ en cada iteración $i$.

    Si definimos la factorización hasta el $k$-ésimo primo de un número $x$ como:
    \begin{center}
        \begin{math}
            F_k(x) = x * (\prod_{i=k}^{i=X} p_{i}^{x_i})^{-1}
        \end{math}
    \end{center}

    Podemos proponer el siguiente invariante de la estrategia propuesta:
    \begin{align*}
        Inv:&\ \  0 \leqslant i \leqslant min(M, N) \\
            &\land (mcd' \mathrel{|} F_i(m)) \land (mcd' \mathrel{|} F_i(n)) \\
            &\land (\forall d: (d \mathrel{|} F_i(m)) \land (d \mathrel{|} F_i(n)) : d \leq mcd') 
    \end{align*}

    Y probar que la siguiente actualización de $mcd'$ e $i$, mantiene dicho invariante
    \begin{align*}
        & mcd' := mcd' * p_{i}^{min(m_{i}, n_{i})} \\
        & i := i + 1
    \end{align*}

    Para realizar esta actualización necesitaríamos contar con $p_{i}$, $m_{i}$ y $n_{i}$. Para eso podríamos introducir funciones auxiliares que nos provean los primeros $N$ primos y la factorización. Pero nos detenemos aquí en cambio, porque no nos interesa seguir este camino. La resolución propuesta parece correcta, sin embargo su complejidad es mucho mayor a la de la solución propuesta por Euclides hace más de 2300 años.

    Hay alguna técnica de obtención de invariantes que nos hubiera llevado a la misma realización que tuvo Euclides? Puede el método reemplazar a la creatividad?
    Euclides --sospecho-- no llegó a proponer su algoritmo manipulando ecuaciones, sino observando líneas geométricas de longitud discreta. De la misma forma en que Pitágoras llegó a su famoso teorema observando triángulos. De nuevo, sospecho.

    El mismo Dijkstra, en su trabajo ``Guarded Commands''\cite{EWD:EWD418} donde presenta su cálculo para la derivación formal de programas reflexiona en las conclusiones:

    \vspace{1em}
    \begin{quoting}
        La segunda razón para llevar a cabo estas investigaciones fue mi deseo personal de apreciar mejor qué parte de la actividad de programación puede considerarse una mera rutina formal y qué parte parece requerir ``invención''. Mientras que el diseño de un \textit{if} parece ahora una actividad bastante directa, el diseño de un ciclo requiere lo que yo considero ``la invención'' de una relación invariante y una función variante.(...) Mi presentación de este cálculo no debe ser interpretada como una sugerencia personal de que todos los programas tiene que ser desarrollados de esta manera: solo nos provee una herramienta más.
    \end{quoting} Edsger W. Dijkstra. (La traducción es mía)
    \vspace{1em}

    En el libro Cálculo de Programas, actual bibliografía de referencia de la materia, se reserva un lugar de gran relevancia a la técnica de derivación de programas. Por ejemplo, para el problema del máximo común divisor se plantea derivar el cuerpo del ciclo a partir de las propiedades del $mcd$ en las que se apoya el algoritmo de Euclides.
    Si bien la técnica es ciertamente valiosa, en mi opinión sería más provechoso enfocar la enseñanza en el razonamiento procedural que realizó Euclides y que explica por qué se eligen dichas propiedades del $mcd$ en primer lugar.

    En general creo que podemos quitar relevancia a la derivación de programas como método preferente para construirlos, dar lugar a otros métodos como la creatividad y el ingenio y resaltar en cambio el rol de las técnicas de verificación formal a la hora de \textbf{probar} que los programas son correctos.

    Probar que el algoritmo de Euclides es correcto, es una tarea tan importante como la demostración de cualquier teorema. En ese sentido no hay diferencia entre un programa y una equivalencia matemática. Ambos pueden obtenerse a partir de un proceso creativo, y necesitan ser demostradas, bajo un proceso metódico, cuidadoso y formal.

    Mi siguiente paso fue entonces observar el procedimiento propuesto por Euclides y entender la estrategia resolutiva para luego pasar a construir una implementación verificada en Dafny.

    \section{El algoritmo de Euclides}
    \label{desarrollo_euclides}
    Euclides propuso pensar en $m$ y $n$ como dos varillas de largo $m$ unidades y $n$ unidades como se ilustra en la Figura \ref{varillas_euclides}, y buscar la varilla de largo $d$ más larga que logre componer ambas de manera exacta.
    
    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Draw the bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            \draw[fill=green!50] (\m*\scale, 0) rectangle (\m*\scale+ \n*\scale, 0.5);% Second bar

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\m*\scale + \n*\scale/2, 0.25) {\textbf{n}};

        \end{tikzpicture}
        \caption{Las varillas de Euclides} \label{varillas_euclides}
    \end{figure}

    Que $d$ pueda componer a ambas, es otra forma de decir que $d \mid m$ y $d \mid n$. Que sea la más larga entre las que pueden componerlas quiere decir que $d = mcd(m,n)$.

    Si la más pequeña puede componer a la más grande (i.e. $n \mid m$), entonces ya está: $d=n=mcd(m,n)$, pues cualquier otra varilla que compone a $n$ es necesariamente menor o igual a $n$. Sino, tenemos que $n$ entra alguna cantidad $q$ de veces en $m$ y luego queda un resto $r$ (Figura \ref{varillas_euclides_resto}).

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Top bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            % Bottom bars
            \draw[fill=green!50] (0, 0.5) rectangle (\n*\scale, 1);
            \draw[fill=green!50] (\n*\scale, 0.5) rectangle (2 * \n*\scale, 1);
            \draw[fill=red!50] (2*\n*\scale, 0.5) rectangle (2 * \n*\scale + \scale, 1);

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\n*\scale/2, 0.75) {\textbf{n}};
            \node at (\n*\scale + \n*\scale/2, 0.75) {\textbf{n}};
            \node at (2 * \n*\scale + \scale/2, 0.75) {\textbf{r}};

        \end{tikzpicture}
        \caption{$n$ no logra componer a $m$, y tenemos un resto $r$} \label{varillas_euclides_resto}
    \end{figure}


    En este caso, la varilla de largo $d$ que estamos buscando debe componer también a $r$. Veamos por qué. Tenemos por un lado que $d$ compone a $n$ y $d$ compone a $m$. Por otro, $m$ está compuesta por una cantidad $q$ de varillas $n$ y un resto $r$.
    Las $q$ varillas de largo $n$ las sabemos compuestas por $d$, por tanto lo que resta ($r$), debe poder componerse con $d$ para que el total $m$ quede compuesto por $d$ a su vez. Si quedara un resto al intentar componer $r$ con $d$, tendríamos en cambio que $d$ no compone $m$ (Figura \ref{varillas_euclides_mcd_del_resto}).

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\bd{0.8} % Length of falsy mcd bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Top bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            % Bottom bars
            \draw[fill=green!50] (0, 0.5) rectangle (\n*\scale, 1);
            \draw[fill=green!50] (\n*\scale, 0.5) rectangle (2 * \n*\scale, 1);
            \draw[fill=red!50] (2*\n*\scale, 0.5) rectangle (2 * \n*\scale + \scale, 1);
            \draw[fill=orange!50] (0, 1) rectangle (\bd, 1.5);
            \draw[fill=orange!50] (\bd, 1) rectangle (2*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 2, 1) rectangle (3*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 3, 1) rectangle (4*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 4, 1) rectangle (5*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 5, 1) rectangle (6*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 6, 1) rectangle (7*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 7, 1) rectangle (8*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 8, 1) rectangle (9*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 9, 1) rectangle (10*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 10, 1) rectangle (11*\bd, 1.5);
            \draw[fill=red!75] (\bd * 11, 1) rectangle (\m*\scale, 1.5);

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\n*\scale/2, 0.75) {\textbf{n}};
            \node at (\n*\scale + \n*\scale/2, 0.75) {\textbf{n}};
            \node at (2 * \n*\scale + \scale/2, 0.75) {\textbf{r}};
            \node at (\bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 1 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 2 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 3 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 4 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 5 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 6 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 7 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 8 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 9 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 10 + \bd/2, 1.25) {\textbf{d}};

        \end{tikzpicture}
        \caption{Si $d$ pudiera componer a $n$ pero no a $r$, tampoco compondría a $m$}
        \label{varillas_euclides_mcd_del_resto}
    \end{figure}

    Sea $r = m \% n$ (el módulo), tenemos entonces dos casos: a) $r = 0 \land d = n$ ó b) $r > 0 \land d \mid r $. En el caso b), como $d \mid n$ y $d \mid r$, tenemos que $d \leq mcd(n, r)$. Veamos además que $d = mcd(n,r)$ probando que $d \geqslant mcd(n,r)$. Como $m = q * n + r$, tenemos que $mcd(n, r) | m$ y por tanto $d \geqslant mcd(n,r)$. Por tanto lo tanto $d = mcd(n,r)$.

    Es decir que los dos casos son: a) $r = 0 \land d = n$ ó b) $r > 0 \land d = mcd(n, r) $

    En el caso a) no queda nada por hacer, en el caso b) podemos repetir el razonamiento reemplazando $m$ por $n$ y $n$ por $r$. Y como en cada iteración el resto de la división de $m$ y $n$ siempre será menor a $n$, con el reemplazo propuesto el resto siempre será menor al de la iteración anterior. A su vez, por ser resto de una división, está acotado por abajo en $0$. Por tanto sabemos que en algún momento terminaremos.

    \section{La metodología}
    Implementar el algoritmo de máximo común divisor de Euclides en Dafny de manera tal que el verificador logre verificar nuestra implementación despierta nuevas preguntas y potenciales respuestas sobre \textbf{qué} conocimiento posee el verificador de Dafny y \textbf{cómo o cuándo} puede aplicarlo.

    Dafny sabe acaso que $mcd(m, n) = mcd(n, m\%n)$? Se lo podemos decir? Si se lo decimos, puede aplicarlo en la verificación?
    Las respuestas rápidas son: ``no lo sabe'', ``se lo podemos decir'', y ``hay que ayudarlo a ubicar el nuevo saber en el formato y lugar correcto''.

    Nuestro camino hacia lograr la implementación verificada no fue lineal, sino que tuvo una etapa prematura de probar distintas estrategias ``contra la caja negra''. Sin embargo, el desarrollo puede realizarse de manera metodológica y ordenada, siguiendo estos pasos:
    \begin{enumerate}
        \item Especificar el programa.
        \item Testear la especificación.
        \item Definir el invariante, función de cota y guarda del loop.
        \item Declarar las variables necesarias en el método principal.
        \item Especificar inicialización y cuerpo del loop.
        \item Implementar la inicialización y el cuerpo del loop.
        \item Fortalecer el invariante, en caso de ser necesario.
    \end{enumerate}

    \subsubsection{Especificación del programa}
    Definimos para ello el predicado \textit{es el mcd} que será verdadero si y solo sí $d$ es el máximo común divisor de $m$ y $n$ y el método principal \textit{máximo común divisor} con su precondición sobre $m$ y $n$ y su poscondición:

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate es_el_mcd(d: int, m: int, n: int)
        {
            0 < d <= n &&
            m % d == 0 &&
            n % d == 0 &&
            forall d' :: 
                (0 < d' <= n && m % d' == 0 && n % d' == 0)
                    ==> d' <= d
        }

        method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
            requires 0 < n <= m
            ensures es_el_mcd(mcd, m, n)
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    Tener definido el predicado \textit{es el mcd} nos será útil a continuación para \textit{testear} la especificación y definir el invariante.

    \subsubsection{Testear la especificación}
    Al escribir software verificado, restringimos el espacio para el error humano de la implementación a la definición de la especificación.
    Si no detectamos los errores de especificación antes de pasar a la etapa de implementación, es posible que malinterpretemos los errores de verificación como deficiencias en la implementación o en la capacidad del verificador para realizar la prueba de correctitud, cuando en realidad el problema está siendo arrastrado desde la especificación misma.
    Afortunadamente en Dafny podemos \textit{testear} la especificación.
    El verificador es capaz de validar el predicado \textit{es el mcd} para algunos casos concretos con números pequeños que nos ayudan a ganar seguridad sobre la correctitud de la especificación.\footnote{Se recomienda al lector modificar el predicado o los casos de tests para forzar un error de verificación. En particular ver qué sucede si equivocamos $d' < d$ en vez de $d' <= d$ en el predicado}.

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method test_es_el_mcd(){
            assert es_el_mcd(1, 8, 3);
            assert !es_el_mcd(2, 8, 3);
            assert es_el_mcd(5, 2345, 5000);
            assert !es_el_mcd(4, 2345, 5000);
            assert es_el_mcd(1, 49163, 9113);
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    \subsubsection{Definir el invariante, función de cota y guarda del loop}

    Recordemos que la estrategia algorítmica era, sabiendo que $d$ es tal que $d = mcd(m, n)$, ir seleccionando en cada iteración dos varillas una más larga: $m'$ y otra más corta: $n'$, manteniendo dos afirmaciones:
    \begin{itemize}
        \item $d = mcd(m', n')$ y
        \item sí $n'$ compone a $m'$, entonces $d = n'$.
    \end{itemize}

    Nos será útil definir el invariante como un predicado:

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        predicate invariante(d: int, m': int, n': int) {
            es_el_mcd(d, m', n')
            && (m' % n' == 0 ==> d == n')
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    En la estrategia propuesta, seleccionábamos $m'$ y $n'$ de forma tal que $m'\%n'$ es menor en cada iteración y al llegar a $m'\%n' == 0$ terminábamos. Proponemos entonces como guarda del loop $m'\%n'>0$, y como función de cota $m'\%n'$.

    \subsubsection{Declarar las variables necesarias en el método principal}
    Hay tres variables de tipo $int$ implicadas en el invariante: $d$, $m'$, $n'$.
    Las últimas dos: $m'$, $n'$ tomarán valores concretos en la inicialización y serán actualizadas en cada iteración, mientras que para $d$ no conocemos su valor hasta el final. Lo único que sabemos de $d$ es que al iniciar el programa refiere al $mcd$ de $m$ y $n$ (los parámetros de entrada), y luego en cada iteración equivale también al $mcd$ de las varillas que estamos analizando. Esto convierte a $d$ en una variable especial, que es necesaria para la verificación pero no se computará en tiempo de ejecución del programa. En Dafny estas variables se llaman \textit{ghost variables} y se definen así:

    \vspace{1em}
    \begin{dafny}
ghost var d: int :| p(d);
    \end{dafny}
    \vspace{1em}

    \noindent que leemos como ``Sea d tal que el predicado p vale para d''. Utilizaremos una ghost variable $d$ para referirnos al $mcd$ de $m$ y $n$.

    \vspace{1em}
    \begin{dafny}
ghost var d: int :| mcd(d, m, n);
    \end{dafny}
    \vspace{1em}

    A continuación escribimos la declaración de estas variables al inicio del método.

    \vspace{1em}
    \begin{whitebox}
    \begin{dafny}[gobble=8]
        method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
            requires 0 < n <= m
            // ensures es_el_mcd(mcd, m, n)
        {
    \end{dafny}
    \end{whitebox}
    \begin{redbox}
    \begin{dafny}[gobble=8,firstnumber=5]
            ghost var d: int :| es_el_mcd(d, m, n);
    \end{dafny}
    \end{redbox}
    \begin{whitebox}
    \begin{dafny}[gobble=8,firstnumber=6]
            var m': int, n': int;
        }
    \end{dafny}
    \end{whitebox}
    \vspace{1em}

    \begin{redbox}
        Error: cannot establish the existence of LHS values that satisfy the such-that predicate
    \end{redbox}

    \vspace{1em}

    Al hacerlo notamos que Dafny devuelve un error para la línea 5. \footnote{Hemos comentado la postcondición de manera intencional. Al comentar la postcondición, exigimos menos del verificador y nos aseguramos que el reporte de errores se centre en informar si hay algún problema entre las líneas de implementación que hemos escrito hasta el momento. Si no comentábamos la postcondición, el verificador nos hubiera devuelto un error relativo al incumplimiento de la postcondición y solo nos enteraríamos de este problema previo más adelante, al especificar inicialización y cuerpo del loop. Tal vez esta sea una oportunidad de mejora en el reporte de errores del verificador. Ver \href{https://github.com/dafny-lang/dafny/issues/6122}{issue 6122 en dafny}.}
    Nosotros sabemos que para dos números enteros positivos existe un máximo común divisor pero Dafny no lo sabe. Podemos decírselo definiendo un axioma que establezca que el máximo común divisor entre $m$ y $n$ existe e invocándolo justo antes de la definición de $d$. \footnote{Un axioma en Dafny es un lemma que no conlleva una prueba. Si quitamos :axiom, Dafny nos pedirá que escribamos la prueba en el cuerpo del lemma.}

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        lemma {:axiom} existe_un_mcd(m:int, n:int)
            ensures exists d: int :: es_el_mcd(d, m, n)

        method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
            requires 0 < n <= m
            // ensures es_el_mcd(mcd, m, n)
        {
            assert exists d: int :: es_el_mcd(d, m, n) by {
                existe_un_mcd(m, n);
            }
            ghost var d: int :| es_el_mcd(d, m, n);
            var m': int, n':int;
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    Con la introducción del axioma, el error de verificación desaparece. La construcción \textit{assert ... by} indica que utilizamos ese lemma para concluir la condición del assert.

    \subsubsection{Especificar inicialización y cuerpo del loop.}

    Cuando invocamos un método auxiliar desde un método principal, para la verificación de este último Dafny asume que el primero cumple con su especificación y se limita a verificar el método principal bajo esa asunción. Haciendo uso de esta decisión de diseño podemos definir métodos con su especificación para la inicialización y cuerpo del loop, y utilizarlos en el método principal antes de pasar a implementarlos.

    En la inicialización, requeriremos como precondición la misma precondición sobre los parámetros de entrada que tiene nuestro método principal, sumado a la condición que impusimos sobre la variable ghost $d$, luego pedimos que la inicialización asegure el invariante de modo que se satisfaga al ingresar al loop.

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method inicializacion(ghost d: int, m: int, n: int)
            returns (m': int, n': int)
            requires 0 < n <= m
            requires es_el_mcd(d, m, n)
            ensures invariante(d, m', n')
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    En la especificación del cuerpo pedimos que la guarda y el invariante se cumplan antes de la ejecución y aseguramos que luego de ejecutar el cuerpo el invariante se sigue cumpliendo y que la función de cota se redujo.


    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method cuerpo(ghost d: int, m: int, n: int)
            returns (m': int, n': int)
            requires invariante(d, m, n)
            ensures invariante(d, m', n')
            ensures m' % n' < m % n
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    Ahora, como decíamos, podemos invocar estos métodos en el método principal e intentar obtener una implementación verificada del mismo. Si lo logramos, habremos validado la elección del invariante, la función de cota y la guarda incluso antes de implementar el cuerpo del loop y su inicialización.


    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
            requires 0 < n <= m
            ensures es_el_mcd(mcd, m, n)
        {
            assert exists d: int :: es_el_mcd(d, m, n) by {
                existe_un_mcd(m, n);
            }
            ghost var d: int :| es_el_mcd(d, m, n);
            var m': int, n':int , r: int;
            m', n' := inicializacion(d, m, n);
            while (m' % n' > 0)
                decreases m' % n'
                invariant invariante(d, m', n')
            {
                m', n' := cuerpo(d, m', n');
            }
            return n';
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}


    \begin{warningbox}{Introducción de inconsistencia}
    Cuando Dafny asume que los métodos auxiliares cumplen con la especificación, lo hace incluso si la especificación es inconsistente. Como se ilustra en el siguiente ejemplo:

    \vspace{1em}
    \begin{greenbox}
    \begin{dafny}[gobble=8]
        method auxiliar (y: int) returns (y': int)
            ensures y' >= 0
            ensures y' < 0

        method principal() {
            var y: int := 1;
            y := auxiliar(y);
            assert false;
        }
    \end{dafny}
    \end{greenbox}
    \vspace{1em}

    A partir de la inconsistencia puede probarse cualquier cosa, incluso \textit{false}, como sucede aquí. Cuando tengamos dudas sobre las condiciones que Dafny está logrando verificar, podemos asegurarnos de que no hay inconsistencias introduciendo \inlinedafny{assert false} y chequeando que falla la verificación.
\end{warningbox}

\subsubsection{Implementar la inicialización y el cuerpo del loop.}

    Con la siguiente implementación del método de inicialización, la verificación del mismo sale de forma directa, como es de esperar a partir del axioma de la asignación.

    \begin{dafny}
method inicializacion(ghost d: int, m: int, n: int)
    returns (m': int, n': int)
    requires 0 < n <= m
    requires es_el_mcd(d, m, n)
    ensures invariante(d, m', n')
    {
        m' := m;
        n' := n;
    }
    \end{dafny}

    Si postulamos para el cuerpo del loop la asignación a $m'$ y $n'$ que obtuvimos en el desarrollo de la sección \ref{desarrollo_euclides} veremos que el verificador sobrepasa el límite de tiempo permitido antes de lograr verificar la implementación.

    \begin{dafny}
method cuerpo(ghost d: int, m: int, n: int)
    returns (m': int, n': int)
    requires invariante(d, m, n)
    ensures invariante(d, m', n')
    ensures m' % n' < m % n
{
    var r := m % n;
    m' := n;
    n' := r;
}
    \end{dafny}

    Sucede que Dafny no conoce la propiedad $mcd(m, n) = mcd(n, m\%n)$, que es junto al teorema de la asignación la clave para poder probar el método. Si introducimos un axioma que establezca esa propiedad, Dafny logra utilizarlo efectivamente para verificar la implementación del cuerpo.

    \begin{dafny}
lemma {:axiom} mcd_del_modulo(d:int, m:int, n:int)
    requires es_el_mcd(d, m, n)
    requires n > 0
    ensures es_el_mcd(d, n, m % n)

method cuerpo(ghost d: int, m: int, n: int)
    returns (m': int, n': int)
    requires invariante(d, m, n)
    ensures invariante(d, m', n')
    ensures m' % n' < m % n
{
    assert es_el_mcd(d, n, m % n) by {
        mcd_del_modulo(d, m, n);
    }
    var r := m % n;
    m' := n;
    n' := r;
}
    \end{dafny}

    La versión final verificada del algoritmo de Euclides para el máximo común divisor, con todos los componentes reunidos, será \footnote{
    Una implementación de este algoritmo utilizando las propiedades de $mcd(m, n) == mcd(m, m - n)$ si $m \ge n$ y la de simetría, puede encontrarse en la serie Dafny Power User de Rustan Leino: \href{https://leino.science/papers/krml279.html}{Case study of definitions, proofs, algorithm correctness: GCD
    }. Leino define la función GCD como el máximo elemento en la intersección de los conjuntos de divisores de $m$ y $n$ y luego utiliza esta función en la especificación del método. Incluye también las pruebas de los lemmas necesarios. Se recomienda su lectura como complemento de esta sección.}:

    \dafnyfile{Versión final del máximo común divisor en Dafny}{ejemplos/mcd/mcd.dfy}

    \subsubsection{Fortalecer el invariante}
    Como veremos en próximos ejemplos, hay ocasiones en que el invariante elegido resulta suficiente para establecer la poscondición desde la perspectiva del método principal, pero para la implementación del cuerpo del loop requerimos de variables auxiliares con sus propios invariantes que posibilitan establecer el invariante original.
    En estos casos decimos que fortalecemos el invariante y en términos prácticos nos llevará a repetir los pasos 3 a 6, agregando las nuevas variables auxiliares y modificando el invariante para que las contemple.

    \subsubsection{Nota sobre los lemmas}
    Nuestro primer intento para los lemmas \textit{existe\_el\_mcd} y \textit{mcd\_del\_modulo} fue declararlos de la siguiente manera:

    \begin{dafny}
lemma {:axiom} existe_el_mcd()
    ensures forall m, n :: 0 < n <= m ==>
        exists d: int :: es_el_mcd(d, m, n)

lemma {:axiom} mcd_del_modulo()
    ensures forall d, m, n : int :: 0 < d <= n <= m ==>
        (es_el_mcd(d, m, n) <==> es_el_mcd(d, m, m % n))
    \end{dafny}

    E invocarlos al inicio del método principal. Pero Dafny no logra verificar el programa de esta manera. A esto nos referíamos con la pregunta de \textbf{cómo o cuándo} puede aplicar Dafny los lemmas y axiomas que le proveemos. Conviene facilitarle a Dafny los lemas de forma tal que el verificador pueda hacer \textit{pattern-matching} entre las variables que están en el scope donde el lemma es necesario y sus parámetros de entrada.

    \chapter{Aplicando la metodología a nuevos problemas}

    \section{Suma del segmento de suma máxima}

    En este problema, el objetivo es averiguar la sumatoria de los elementos del segmento contiguo de suma máxima en un arreglo de números enteros.
    Como el arreglo puede contener números negativos, la solución no siempre es el segmento equivalente al total del arreglo.

    El problema del segmento de suma máxima fue resuelto por Joseph Kadane con un algoritmo de $\mathcal{O}(N)$ el cuál analizaremos a continuación.

    \subsubsection*{El algoritmo de Joseph Kadane}
    Visualizaremos el arreglo como una lista de cinco cartas de poker puestas boca abajo, que descubrimos una a una de izquierda a derecha. Utilizaremos cartas de corazón para representar números positivos, y cartas de trébol para números negativos.

    La idea es que en cada paso, tendremos una solución subóptima que será la suma de segmento máxima para los segmentos conocidos hasta el momento (con las cartas ya descubiertas), de modo que al descubrir todas las cartas, tendremos la suma del segmento de suma máxima para todo el arreglo.

    Veamos un caso concreto en el que hemos descubierto ya las primeras dos cartas y estamos a punto de descubrir la tercera (ver figura \ref{desc_ter_carta}).

    \ifUsePstPoker
        \begin{figure}[h]
            \centering
            \psset{framebg=beige}\crdsevh
            \psset{framebg=beige}\crdtwoh
            \psset{backcolor=red}\crdback
            \psset{backcolor=red}\crdback
            \psset{backcolor=red}\crdback
            \rput(-8.2,-1){\textbf{\^}} % Positioning the ^ character

            \caption{Descubriendo la tercera carta} \label{desc_ter_carta}
        \end{figure}
    \fi

    El segmento de suma máxima conocido hasta el momento es el compuesto por las dos primeras cartas. Al descubrir la tercera pueden pasar dos cosas:
    \begin{itemize}
        \item O bien, la carta es de corazones y nos sirve para formar un nuevo segmento de suma máxima, pues incluirla resulta en un segmento con sumatoria mayor a la conocida hasta ahora.
        \item O bien, la carta es de trébol y entonces el segmento de suma máxima conocido hasta el momento es el que ya conocíamos en la iteración anterior.
    \end{itemize}

    Supongamos que descubrimos la tercera carta, resulta ser un diez de trébol y pasamos a descubrir la cuarta carta (ver figura \ref{desc_cuarta_carta}).

    \ifUsePstPoker
        \begin{figure}[h]
            \centering
            \psset{framebg=beige}\crdsevh
            \psset{framebg=beige}\crdtwoh
            \psset{framebg=beige}\crdtenc
            \psset{backcolor=red}\crdback
            \psset{backcolor=red}\crdback
            \rput(-4.8,-1){\textbf{\^}} % Positioning the ^ character

            \caption{Descubriendo la cuarta carta} \label{desc_cuarta_carta}
        \end{figure}
    \fi

    \noindent En este caso el segmento de suma máxima conocido hasta el momento es el compuesto únicamente por las dos primeras cartas. Al descubrir la cuarta carta tenemos las siguientes posibilidades:
    \begin{itemize}
        \item Es de trébol y el segmento de suma máxima seguirá siendo el ya conocido.
        \item Es de corazón y su valor es mayor a nueve, con lo cuál tenemos un nuevo segmento de suma máxima, compuesto únicamente por esta carta.
        \item Es de corazón pero su valor no es mayor a nueve, con lo cuál el segmento de suma máxima seguirá siendo el ya conocido.
    \end{itemize}

    Pongamos que la cuarta carta es un dos de corazones y volvamos a analizar el escenario (ver figura \ref{desc_quinta_carta}).

    \ifUsePstPoker
        \begin{figure}[h]
            \centering
            \psset{framebg=beige}\crdsevh
            \psset{framebg=beige}\crdtwoh
            \psset{framebg=beige}\crdtenc
            \psset{framebg=beige}\crdtwoh
            \psset{backcolor=red}\crdback
            \rput(-1.8,-1){\textbf{\^}} % Positioning the ^ character

            % Place an arrow at the bottom of the third card
            \caption{Descubriendo la quinta carta} \label{desc_quinta_carta}
        \end{figure}
    \fi

    Ahora las posibilidades al descubrir la quinta carta son:
    \begin{itemize}
        \item Es de trébol y el segmento de suma máxima seguirá siendo el ya conocido.
        \item Es de corazón y su valor sumado al dos anterior es mayor a nueve, con lo cuál tenemos un nuevo segmento de suma máxima, compuesto por el dos y esta quinta carta.
        \item Es de corazón pero su valor sumado al dos anterior no es mayor a nueve, con lo cuál el segmento de suma máxima seguirá siendo el ya conocido.
    \end{itemize}

    Notemos que siempre sucede que, si logramos obtener un nuevo segmento de suma máxima al descubrir una nueva carta, este será el segmento resultante de agregar la nueva carta al segmento de suma máxima que hayamos logrado hasta el momento incluyendo la carta anterior, en el caso de que hayamos logrado acumular una suma positiva como en la figura \ref{desc_quinta_carta}, o será por que esta carta por sí sola constituye el nuevo segmento de suma máxima, como podría haber sucedido en la figura \ref{desc_cuarta_carta}

    En todo caso, si en cada iteración conocemos por un lado, la suma del segmento de suma máxima conocido hasta el momento y por otro, la suma del segmento de suma máxima que incluye a la carta anterior, y en particular conocemos esto en la última iteración al descubrir la última carta, entonces tendremos toda la información necesaria para determinar el segmento de suma máxima del arreglo. Habremos logrado resolver el problema recorriendo una sola vez el arreglo.

    Formalicemos ahora el problema y la estrategia resolutiva para obtener una implementación verificada en Dafny.

    \subsubsection*{Implementación en Dafny}
    Identificaremos un segmento con dos índices $p,q$, donde $p$ es el índice del primer elemento del segmento y $q-1$ el del último elemento.

    El segmento vacío denotado por dos índices idénticos cualquiera (ejemplo: $i,i$) tiene suma 0.

    El primer paso entonces es especificar el programa. Para ello definimos la función recursiva \textit{suma} para denotar la suma del segmento $p,q$ de un arreglo $A$.
    Y un predicado para la suma máxima que utilizamos como poscondición del método principal.

    \begin{dafny}
function suma(p:nat, q:nat, A: seq<int>): int
    requires 0 <= p <= q <= |A|
{
    if q <= p then 0 else suma(p, q-1, A) + A[q-1]
}

predicate es_suma_maxima(A: seq<int>, r: int) {
    (exists p, q :: 0 <= p <= q <= |A| && suma(p, q, A) == r) &&
    (forall i, j :: 0 <= i <= j <= |A| ==> suma(i, j, A) <= r)
}

method segmento_de_suma_maxima(A: seq<int>) returns (r: int)
    ensures suma_maxima(A, r)
    \end{dafny}

    A continuación escribimos algunos casos simples de prueba para ganar confianza en la especificación de la función \textit{suma} y el predicado \textit{es\_suma\_maxima}

    \begin{dafny}
method test_suma()
{
    assert suma(0, 3, [1,2,-3,4,5]) == 0;
    assert suma(0, 4, [1,2,-3,4,5]) == 4;
    assert suma(3, 5, [1,2,-3,4,5]) == 9;
    assert suma(4, 4, [1,2,-3,4,5]) == 0;
}

method test_es_suma_maxima()
{
    assert es_suma_maxima([1,2,-3], 3);
    assert suma(0, 3, [1,2,3]) == 6;
    assert es_suma_maxima([1,2,3], 6);
}
    \end{dafny}

    Ahora formalicemos un invariante, una guarda y una función de cota para el ciclo del programa. Utilizaremos $k$ para referenciar la iteración $k$-ésima, $A$ para el arreglo de entrada, $r$ para denotar la suma del segmento de suma máxima conocido hasta el momento.

    \begin{dafny}
predicate invariante(k: int, A: seq<int>, r: int){
    0 <= k <= |A| &&
    (exists p, q :: 0 <= p <= q <= k && suma(p, q, A) == r) &&
    (forall i, j :: 0 <= i <= j <= k ==> suma(i, j, A) <= r) &&
}
    \end{dafny}

    Notar que aún no hemos incluído en el invariante la suma de segmento máxima para segmentos que incluyan al último elemento conocido. Lo cual resultará necesario más adelante cuando intentemos verificar una implementación del cuerpo del loop que sostenga el invariante.

    Para la guarda postulamos $k < |A|$. Y para la función de cota $|A| - k$. Probemos ahora inicializar las variables con métodos de inicialización y cuerpo que aún no implementaremos pero especificaremos en relación al invariante y la guarda.

    \begin{dafny}
method inicializacion(A: seq<int>) returns (k: int, r: int)
    ensures invariante(k, A, r)

method cuerpo(k: int, A: seq<int>, r: int) returns (k': int, r': int)
    requires k < |A|
    requires invariante(k, A, r)
    ensures invariante(k', A, r')
    ensures k' > k

method segmento_de_suma_maxima(A: seq<int>) returns (r: int)
    ensures es_suma_maxima(A, r)
{
    var k: int;
    k, r := inicializacion(A);
    while (k < |A|)
        decreases |A| - k
        invariant invariante(k, A, r)
    {
        k, r := cuerpo(k, A, r);
    }
}
    \end{dafny}

    La verificación del método \textit{segmento\_de\_suma\_maxima} resulta satisfactoria tras haber asumido que la inicialización y el cuerpo cumplen con su especificación. Podemos pasar ahora a implementar estos últimos.

    \begin{dafny}
method inicializacion(A: seq<int>) returns (k: int, r: int)
    ensures invariante(k, A, r)
{
    k := 0;
    r := 0;
    assert suma(0, 0, A) == 0;
}
    \end{dafny}

    Para la inicialización, la única ayuda que tuvimos que darle a Dafny es inducirlo a probar que la suma del segmento vacío $0,0$ en $A$ es igual a 0 (utilizando el assert de la línea 6). Con lo cuál puede probar por sí mismo el resto del invariante.

    En cuanto nos disponemos a implementar el cuerpo notamos que no contamos con una variable que albergue la suma del segmento de suma máxima incluyendo el elemento anterior, que era necesario para computar el nuevo segmento de suma máxima.
    Utilizaremos $u$ para albergar la suma del segmento de suma máxima que incluye a $A[k-1]$, o del segmento vacío (con suma $0$) en caso de que no hayamos logrado acumular una suma positiva que incluya a $A[k-1]$. Por tanto, actualizamos el invariante con una cláusula sobre $u$ y con él la inicialización y la declaración de variables en el método principal.

    \begin{dafny}
predicate invariante(k: int, A: seq<int>, r: int, u: int){
    0 <= k <= |A| &&
    (exists p_u :: 0 <= p_u <= k && suma(p_u, k, A) == u) &&
    (forall i :: 0 <= i <= k ==> suma(i, k, A) <= u) &&
    (exists p, q :: 0 <= p <= q <= k && suma(p, q, A) == r) &&
    (forall i, j :: 0 <= i <= j <= k ==> suma(i, j, A) <= r)
}
    \end{dafny}

    Hemos agregado, de forma intencional, las nuevas cláusulas sobre $u$ antes de las cláusulas sobre $r$. Esto es por que sabemos que el verificador necesitará de las nuevas cláusulas para poder probar las cláusulas sobre $r$. Por tanto es buena idea presentárselas en ese orden. Si el verificador no puede probar las cláusulas para $u$ la verificación se detendrá allí y el mensaje de error será más acotado.

    Con el nuevo invariante postulamos la implementación del cuerpo del loop.

    \begin{dafny}
method cuerpo(k: int, A: seq<int>, r: int, u:int) returns (k': int, r': int, u': int)
    requires k < |A|
    requires invariante(k, A, r, u)
    ensures invariante(k', A, r', u')
    ensures k' > k
{
    if u + A[k] < 0 {
        u' := 0;
    } else {
        u' := u + A[k];
    }
    if u' > r {
        r' := u';
    } else {
        r' := r;
    }
    k' := k + 1;
}
    \end{dafny}

    El primer \textit{if-else} define el valor de $u'$, que será el resultado de sumar el nuevo elemento a $u$ en caso de que esta suma resulte no negativa. De lo contrario debemos asignar a $u'$ la suma del segmento vacío.
    El segundo \textit{if-else} define el valor de $r'$, que será $u'$ en caso de que este supere al segmento de suma máxima conocido hasta ahora, o tendrá el valor de este último en caso contrario.

    El verificador en este caso falla en realizar la prueba con el error: ``Could not prove: \inlinedafny{exists p_u :: 0 <= p_u <= k && suma(p_u, k, A) == u}''

    Ayudemos al verificador en el razonamiento, como vimos al estudiar la regla del \textit{if}, podemos hacer el análisis caso por caso. En el caso $u + A[k] > 0$, tenemos que el mismo $p_u$ para el cual la cláusula se cumplía con $k$ y $u$ valdrá para $k'=k+1$ y $u'=u + A[k]$.
    Y en el caso $u + A[k] <= 0$ sabemos que $suma(k+1, k+1, A) = u' = 0$.
    Podemos inducir a Dafny a verificar estas condiciones mediante cláusulas \textit{assert} en cada caso del \textit{if-else}.

    \begin{dafny}
if u + A[k] < 0 {
    u' := 0;
    assert suma(k+1, k+1, A) == u';
} else {
    u' := u + A[k];
    ghost var p_u :| 
        (0 <= p_u <= k && suma(p_u, k, A) == u)
        && (forall i :: 0 <= i <= k ==> suma(i, k, A) <= u);
    assert suma(p_u, k+1, A) == u';
}
    \end{dafny}

    Con esta ayuda, Dafny logra verificar el método cuerpo y consecuentemente la implementación de todo el programa, la cual recopilamos a continuación.

    \dafnyfile{Implementación verificada de segmento de suma máxima}{ejemplos/calculo_de_programas/segmento_de_suma_maxima.dfy}

    \section{Búsqueda de subcadenas}
    El algoritmo de búsqueda de subcadena consiste en encontrar una ocurrencia de una cadena de caracteres $w$ dentro de otra cadena $s$ y devolver el índice del primero de los caracteres de tal ocurrencia. Podemos especificarlo en Dafny de la siguiente manera:

    \begin{dafny}
predicate esta_en(s: string, w: string, k: int)
{
  0 < |w| <= |s| &&
  0 <= k <= |s| - |w| &&
  forall i: int :: k <= i < k + |w| ==> s[i] == w[i - k]
}

method busqueda_subcadena(s: string, w: string) returns (k: int)
  requires exists j :: esta_en(s, w, j)
  ensures esta_en(s, w, k)
    \end{dafny}

    Luego podemos escribir tests para el predicado \textit{esta\_en} para asegurarnos que nuestro programa está bien especificado.

    \begin{dafny}
method test_esta_en_cuando_esta(){
  assert esta_en("casa", "casa", 0);
  assert esta_en("casa", "cas", 0);
  assert esta_en("casa", "ca", 0);
  assert esta_en("casa", "c", 0);
  assert esta_en("casa", "asa", 1);
  assert esta_en("casa", "as", 1);
  assert esta_en("casa", "a", 1);
  assert esta_en("casa", "sa", 2);
  assert esta_en("casa", "s", 2);
  assert esta_en("casa", "a", 3);
}
    \end{dafny}

    Dafny es capaz de verificar todos estos casos de forma directa. Veamos qué sucede para el caso en que $w$ no está en $s$.

    \begin{dafny}
method test_esta_en_cuando_no_esta(){
    assert !esta_en("casa", "d", 0);
}
    \end{dafny}

    En este caso el verificador no logra asegurar que ``d'' no está en ``casa''. Los casos de test no son ejecuciones de código. Son obligaciones de prueba para el verificador y como tales, a veces se resuelven de forma directa y a veces hay que ayudar al verificador con lemmas o hints para la prueba.

    En este caso, podemos introducir un lemma que establece que si $w$ está en $s$ en la posición $k$ entonces el primer caracter de $w$ y el caracter de $k$ de $s$ coinciden.

    \begin{dafny}
lemma si_esta_coincide_el_primer_caracter()
    ensures forall s:string, w: string, k: int ::
                esta_en(s, w, k)) ==> s[k] == w[0]
{
}

method test_esta_en_cuando_no_esta(){
    assert !esta_en("casa", "d", 0) by {
        si_esta_coincide_el_primer_caracter();
    }
}
    \end{dafny}

    Con la especificación testeada proseguimos a proponer un invariante y una guarda. Realizaremos la implementación más simple de la búsqueda de subcadenas, en la cuál iteraremos todas las posiciones de $s$ desde la primera y verificaremos el predicado \textit{esta\_en} evaluado en esta posición hasta encontrar la primera para la cuál se cumple. Tendremos como precondición que $w$ está en $s$ para algún índice $j$.

    Inicialmente proponemos como guarda: \inlinedafny{!esta_en(s, w, i)} donde i es la variable de iteración y como invariante $true$. Ya que la negación de la guarda por sí misma asegura la poscondición si luego retornamos $i$.

    \begin{dafny}
predicate esta_en(s: string, w: string, k: int)
{
  0 < |w| <= |s| &&
  0 <= k <= |s| - |w| &&
  forall i: int :: k <= i < k + |w| ==> s[i] == w[i - k]
}

predicate invariante(){
  true
}

method inicializacion(s: string, w: string, ghost k: int)
  returns (i: int)
  requires esta_en(s, w, k)
  ensures invariante()

method cuerpo(s: string, w: string, ghost k: int, i: int)
  returns (i': int)
  requires !esta_en(s, w, i)
  requires invariante()
  ensures invariante()
  ensures i' > i

method busqueda_subcadena(s: string, w: string)
  returns (k: int)
  requires exists j :: esta_en(s, w, j)
  ensures esta_en(s, w, k)
{
  ghost var gk: int :| esta_en(s, w, gk);
  var i: int;
  i := inicializacion(s, w, gk);
  while (!esta_en(s, w, i))
    decreases gk - i
    invariant invariante()
  {
    i := cuerpo(s, w, gk, i);
  }
  return i;
}
    \end{dafny}

    Hemos utilizado una variable de tipo ghost $gk$ para referenciar la posición en la que sabemos que $w$ está presente dentro de $s$. Proponemos como función de cota $gk - i$.
    También hemos especificado la inicialización de $i$ y el cuerpo de forma tal que aseguren el invariante y el decrecimiento de la función de cota.

    El verificador devuelve el siguiente error: "decreases expression must be bounded below by 0 at end of loop iteration". Dafny logra verificar que $gk -i$ decrece, pero no sabe si está limitada por 0 por lo bajo. Agregamos al invariante entonces $i \leq gk$. Ahora Dafny verifica la implementación del método principal, y podemos abocarnos a implementar inicialización y cuerpo.

    Inicializar $i$ en $0$ basta para cumplir el invariante:

    \begin{dafny}
method inicializacion(s: string, w: string, ghost k: int) returns (i: int)
  requires esta_en(s, w, k)
  ensures invariante(i, k)
{
  return 0;
}
    \end{dafny}

    Pero el nuevo invariante no puede asegurarse con la implementación del cuerpo que sabemos suficiente: incrementar la variable de iteración $i$ en $1$.

    \begin{dafny}
method cuerpo(s: string, w: string, ghost k: int, i: int) returns (i': int)
  requires !esta_en(s, w, i)
  requires invariante(i, k)
  ensures invariante(i', k)
  ensures i' > i
{
  i' := i + 1;
}
    \end{dafny}
    El verificador devuelve el error: ``this postcondition could not be proved on a return path
    Could not prove: i <= k'', para el método cuerpo.
    Es que, para saber que $i+1<=k$ falta una pieza clave que es saber \inlinedafny{esta_en(s, w, k)}, que junto con \inlinedafny{!esta_en(s, w, i)}, la negación de la guarda y el invariante $i \leq k$, aseguran que $i < k$ y por tanto $i+1 \leq k$.

    Si incluímos \inlinedafny{esta_en(s, w, k)} al invariante, tenemos la implementación completa verificada.

    \dafnyfile{Búsqueda de subcadena en Dafny}{ejemplos/busqueda_subcadena.dfy}

    Algunos aprendizajes de la implementación de este algoritmo fueron:
    \begin{itemize}
        \item Hay que evitar utilizar precondiciones en los predicados. Es decir es mejor escribir:
        \begin{dafny}
predicate esta_en(s: string, w: string, k: int)
{
    0 < |w| <= |s| && 0 <= k <= |s| - |w| &&
    forall i: int :: k <= i < k + |w| ==> s[i] == w[i - k]
}
        \end{dafny}
en comparación con:
        \begin{dafny}
predicate esta_en(s: string, w: string, k: int)
    requires 0 < |w| <= |s| && 0 <= k <= |s| - |w|
{
  forall i: int :: k <= i < k + |w| ==> s[i] == w[i - k]
}
            \end{dafny}
        Estos dos predicados pueden lucir equivalentes, pero el primero podemos utilizarlo siempre (por ejemplo en una cláusula de requires), mientras que el segundo le impone al verificador probar la precondición en contextos en donde tal vez, producto de la modularización, el verificador no puede asegurarla. Si uno mantiene la precondición en el predicado, se ve obligado a sumar una cláusula requires adicional pidiendo también por esta precondición, cada vez que queremos requerir el predicado.
        \item En la práctica podemos empezar postulando un invariante inicial que no sea lo suficientemente fuerte para garantizar la prueba, y tengamos que realizar algunas iteraciones de fortalecimiento de invariante hasta lograrla. En particular, tener de partida en el invariante el rango posible para la variable de iteración y las propiedades conocidas sobre los parámetros de entrada y las variables ghost definidas puede ser una buena decisión por defecto.
    \end{itemize}

    \chapter{El pipeline de verificación de programas Dafny} \label{ch:pipeline-dafny}

    Dafny se apoya en Boogie (un lenguaje intermedio de verificación o IVL, por sus siglas en inglés), para resolver la verificación automática de programas.
    Boogie, como otros IVL, funciona como una capa de abstracción útil en la cual, por arriba, distintos lenguajes con soporte para especificaciones implementan su traducción a Boogie\footnote{
        Boogie fue escrito originalmente como herramienta intermedia del proyecto Spec\#, una extensión de C\# con soporte para especificaciones. Luego tomó vida propia y hoy es utilizado para construir verificadores para otros lenguajes, como el verificador de Dafny para el lenguaje del mismo nombre, o VCC y HAVOC, dos verificadores de C.
    }, y por abajo, Boogie despacha obligaciones de prueba a probadores de teoremas automáticos. En el medio, el IVL, debe encargarse de la generación de esas obligaciones de prueba.

    El pipeline de verificación de programas Dafny se compone entonces, principalmente, por estas tres etapas:
    \begin{itemize}
        \item La traducción del programa Dafny a un programa Boogie.
        \item La generación de obligaciones de prueba a partir del programa Boogie.
        \item La descarga de esas obligaciones de prueba en un SMT Solver, típicamente.
    \end{itemize}

    \section{La traducción de Dafny a Boogie}
    La traducción de Dafny a Boogie no es trivial, la pieza de código que se encarga de ello tiene aproximadamente un millón de líneas escritas en C\#, y codifica cada elemento del lenguaje de Dafny en elementos de Boogie.\footnote{El código fuente para la traducción se encuentra en el \href{https://github.com/dafny-lang/dafny/tree/v4.7.0/Source/DafnyCore/Verifier}{directorio ``Verifier''} del repositorio de Dafny, en donde la clase ``BoogieGenerator'' se construye modularmente a través de múltiples archivos. Dafny además debe encargarse de garantizar trazabilidad entre el código fuente original y los resultados de la verificación obtenidos, a fin de posibilitar un reporte útil de errores.} La expresividad de Boogie posibilita la traducción de lenguajes con múltiples features como Dafny.

    Utilizando la línea de comandos de Dafny podemos obtener la traducción a código Boogie de la siguiente manera
    \begin{verbatim}
        dafny verify my_program.dfy --bprint:my_program.bpl
    \end{verbatim}
    Al hacerlo, nos encontraremos con un programa Boogie mucho más extenso que nuestro programa original en Dafny. Esto es porque la traducción empieza con un preludio\footnote{El código fuente del preludio se encuentra apartado en el \href{https://github.com/dafny-lang/dafny/blob/v4.7.0/Source/DafnyCore/DafnyPrelude.bpl}{directorio ``Prelude''} del repositorio de Dafny}, en el cual se axiomatizan en Boogie todos los elementos de Dafny, (tipos, expresiones, etc), seguido de la traducción en sí de nuestro programa Dafny.

    \section{La generación de obligaciones de prueba}
    La generación de obligaciones de prueba consiste en una serie de transformaciones del programa Boogie inicial, hacia una versión tal que permita la construcción de una fórmula lógica a partir de las sentencias del programa de forma directa.

    Este pipeline fue descripto por Barnett y Leino\cite{10.1145/1108792.1108813} y se recomienda su lectura para entenderlo en detalle. Aquí haremos un repaso de los conceptos principales que allí se describen.

    \subsection*{ El lenguaje no estructurado de partida}
    El pipeline se basa en programas no estructurados que siguen la siguiente gramática:
    \begin{align*}
        Program \;\;&::=\;\; Block^{+} \\
          Block \;\;&::=\;\; BlockId :\; Stmt;\;\textbf{goto } BlockId^{*} \\
           Stmt \;\;&::=\;\; VarId := Expr\;|\;\textbf{havoc } VarId \\
                &\;\;\;\;\;\;\;\;|\ \textbf{assert } Expr\;|\;\textbf{assume } Expr \\
                &\;\;\;\;\;\;\;\;|\ Stmt ; Stmt \;|\; \textbf{skip} \\
    \end{align*}
    En este pequeño lenguaje un programa está compuesto por uno o más bloques. Al primero de ellos lo denominamos $Start$. Cada bloque está identificado por un $BlockId$, tiene un cuerpo compuesto por una o más sentencias y un conjunto de cero o más bloques \textit{sucesores}. Cuando se ejecuta un bloque se, ejecuta primero su cuerpo, y luego se continúa arbitrariamente con alguno de los bloques sucesores. 

    El operador ``$:=$'' denota la asignación, $\textbf{havoc}$ la asignación de un valor arbitrario a una variable. El operador ``$;$'' se utiliza para componer. Las sentencias $\textbf{assert}$ y $\textbf{assume}$ tienen un rol clave en la generación de obligaciones de prueba y $\textbf{skip}$ es simplemente un atajo para $\textbf{assert True}$.

    La transformación de programas estructurados a esta gramática se logra reemplazando ciclos con $\textbf{goto}$'s y condicionales de la forma:
    \begin{align*}
        \textbf{if}\ (E)\ \{S\}\ \textbf{else}\ \{T\}
    \end{align*}
    con:
    \begin{align*}
        Start:&\;\;\;\textbf{skip};\ \textbf{goto}\ Then,\ Else \\
        Then:&\;\;\;\textbf{assume}\ E;\ S;\ \textbf{goto}\ End \\
        Else:&\;\;\;\textbf{assume}\ \lnot E;\ T;\ \textbf{goto}\ End \\
        End:&\;\;\;...
    \end{align*}
    Las precondiciones pueden codificarse incorporando sentencias $\textbf{assume}$ al principio del bloque $Start$ y las postcondiciones como sentencias $\textbf{assert}$ al final de los bloques sin sucesores.
    Cada programa da lugar a un conjunto de trazas de ejecución posibles empezando desde el bloque $Start$. Un programa es correcto si ninguna de ellas contiene una sentencia $\textbf{assert}$ que evalúe a $False$.

    \subsection*{La eliminación de loops}
    A partir de una versión no estructurada del programa siguiendo esta gramática, los ciclos quedan codificados en la forma:
    \begin{align*}
        LoopHead:\;\;\;&\textbf{assert}\ \text{loop invariant};\\
                       &\textbf{goto}\ Body,\ After \\
        Body:\;\;\;&\textbf{assume}\ \text{loop guard};\\
                   &S;\\
                   &\textbf{goto}\ LoopHead \\
        After:\;\;\;&\textbf{assume}\ \lnot \text{loop guard};\\
                    & ...
    \end{align*}

    A continuación se eliminan los loops, eliminando los ``back edges'' (introducidos por las sentencias de tipo $\textbf{goto}\ LoopHead$). Para esto, primero se mueve la aserción del invariante al bloque predecesor de $LoopHead$, reemplazándolo por sentencias $\textbf{havoc}$ sobre las variables que pueden ser modificadas por el loop, seguido de una sentencias $\textbf{assume}$ para el invariante. De esta forma las trazas que pasen por el bloque $Body$ representan cualquier iteración arbitraria del ciclo y la sentencia $\textbf{goto}\ LoopHead$ puede eliminarse del cuerpo.
    Notar que esta transformación denota una fuerte dependencia en la definición de invariantes para los ciclos que, de no ser provistos por el usuario, se generan automáticamente.

    \subsection*{La pasificación o eliminación de las asignaciones}
    Una vez eliminados los loops, se realiza la ``pasificación'' del programa que consiste en eliminar las asignaciones y en su lugar utilizar sentencias $\textbf{assume}$. Para ello primero se introducen variables auxiliares para cada ``encarnación'' o asignación de las variables del programa, asegurando que en cualquier traza de ejecución posible cada variable sea asignada una única vez, lo que permite a continuación transformar estas asignaciones únicas en sentencias $\textbf{assume}$.

    \subsection*{La construcción de la obligación de prueba}
    Concluídas estas dos transformaciones, se obtiene un programa compuesto por bloques de la forma:
    \begin{verbatim}
        A: S; goto ...
    \end{verbatim} 
    Donde $S$ solo puede ser $\textbf{assume}$, $\textbf{assert}$ o composición de estos dos.\footnote{Las sentencias de tipo $\textbf{havoc }$ pueden eliminarse a los fines generar la obligación de prueba, pues ló único que interesa sobre las variables son sus condicionantes expresados en las sentencias de tipo $\textbf{assume}$ y $\textbf{assert}$. Las sentencias de tipo $\textbf{skip}$, recordemos, son un atajo a $\textbf{assert}\ True$.}
    La Weakest Precondition de cada una de estos tipos de sentencias puede definirse como:
    \begin{align*}
        wp(\textbf{assert}\ P,\;Q)   &= P \land Q \\
        wp(\textbf{assume}\  P,\; Q) &= P \Rightarrow Q \\
        wp(S;T,\;Q)                  &= wp(S,\;wp(T,\;Q)) \\
    \end{align*}
    Para cada bloque A, se define la variable auxiliar $A_{ok}$. Intuitivamente $A_{ok}$ es $true$ si el programa está en un estado a partir del cual todas las ejecuciones que empiecen desde A son correctas. Se postula la ``ecuación de bloque'' para definir $A_{ok}$ formalmente:
    \begin{align*}
        A_{ok} \equiv wp(S, \bigwedge_{B \in Succ(A)} B_{ok})
    \end{align*}
    Donde $Succ(A)$ es el conjunto de bloques sucesores de $A$.

    Por último, siendo $R$ la conjunción de las ecuaciones de esta forma aportadas por cada bloque del programa, la obligación de prueba del programa queda definida como:
    \begin{align}
        R \Rightarrow Start_{ok} \label{eq:VC}
    \end{align}

    Se puede ver, siguiendo los detalles que, si el probador de teoremas resuelve \textit{sat} para la negación de la fórmula \ref{eq:VC}:
    \begin{align*}
        R \land \lnot Start_{ok}
    \end{align*}
    Estamos en situación de que existe un estado a partir del cuál, establecida la semántica del programa ($R$), hay una traza de ejecución incorrecta, es decir que el programa no cumple con su especificación.

    \subsection*{Conclusión}

    La generación de obligaciones de prueba que realiza Boogie, busca crear fórmulas lógicas que sean acotadas en tamaño, y eviten redundancia para facilitar la tarea del probador de teoremas.
  
    Utilizando la línea de comandos de Boogie podemos inspeccionar las distintas versiones del programa obtenidas tras realizar cada una de las etapas del pipeline con la opción \verb|\traceverify|
    \begin{verbatim}
        boogie /traceverify ejemplos/my_program.bpl
    \end{verbatim}

    \section{La delegación de las obligaciones de prueba}
    Las obligaciones de prueba, que resultan del proceso descripto en la sección anterior, deben ser despachadas al probador de teoremas.
    Con la opción \verb|/proverLog| podemos ver el registro de la consulta realizada por Boogie al probador de teoremas, en formato de expresiones SMT-LIB y, como comentarios, las respuestas obtenidas:
    \begin{verbatim}
        boogie /proverLog:my_program.smt my_program.bpl
    \end{verbatim}

    \chapter{Conclusiones}
    Dafny es un lenguaje de programación accesible, con una sintaxis fácil de interpretar. La experiencia de escribir programas Dafny en un entorno de desarrollo que integra la verificación automática es enriquecedora. El verificador es rápido y el reporte de errores es claro en sus mensajes y preciso a la hora de indicar en qué segmento del código fuente hubo una condición de verificación que no pudo resolverse.

    Para que la interacción entre el desarrollador y el verificador fluya y favorezca la comprensión, es necesario ser metódicos a la hora de escribir los programas. Presentamos una metodología que ordena el desarrollo y cuyo principio fundamental es particionar el problema en subproblemas más simples (esqueleto del método principal, cuerpo del loop, inicialización). Esta metodología permite compartimentar la interacción con el verificador, evitando escenarios donde los reportes de errores sean potencialmente numerosos y variados, lo que tornaría confusa la tarea de identificar el origen de los mismos.

    Propusimos narrativas para explicar algoritmos no triviales mediante analogías entre dichos algoritmos y procedimientos interactivos del ser humano con objetos del mundo real (por ejemplo, el uso de ``varillas'' para entender el algoritmo de máximo común divisor de Euclides, o de ``cartas'' para el algoritmo de segmento de suma máxima de Kadane). Estas explicaciones resultaron efectivas para entender la estrategia resolutiva en cada caso y despejar los invariantes y funciones de cota que le dan sustento. Mostramos además que complementando estas narrativas con la comprensión de los axiomas y reglas de inferencia de la lógica de Hoare y una metodología para ordenar el desarrollo, se pueden lograr implementaciones verificadas en Dafny de los algoritmos expuestos.

    Estos elementos en su conjunto proponen un acercamiento a la programación formal que puede entenderse como alternativo o complementario a la propuesta académica de la materia Algoritmos y Estructura de Datos I. Creemos que sería de gran valor consolidar esta propuesta en un curso concreto que permita ponerla a prueba y medir resultados de aprendizaje en el estudiantado. Una hipótesis a validar sería que los estudiantes logren, hacia el final del curso, estar en mejores condiciones para explicar los algoritmos aprendidos, proponer algoritmos para problemas nuevos inspirados en los ya conocidos, y obtener implementaciones verificadas por computadora de los mismos.

    Por último, consideramos que delegar la mecanización de las pruebas en un verificador automático permite explorar en el mismo período de tiempo una mayor variedad de programas (por ejemplo, programas con arreglos, punteros y clases), y esto sirva como puente para que los estudiantes sostengan el hábito de la programación formal en proyectos de software de mediano o gran tamaño. Dafny tiene soporte para múltiples tipos y estructuras de datos que no llegamos a visitar durante este trabajo. Consideramos que ampliar la propuesta de enseñanza presentada aquí para que los abarque es una línea de investigación futura interesante.

    \chapter{Misc (a eliminar)}

    \section{WP y condiciones de verificacion}
    De esta manera, si encontramos una demostración de $P \Rightarrow wp.S.Q$, por ejemplo, a partir de un conjunto de axiomas que asumimos como tales y un conjunto de reglas de inferencia correctamente utilizadas, habremos garantizado que el programa cumple con su especificación. O en términos de nuestra pregunta original, que el programa hace lo que tiene que hacer.

    Dafny utiliza el cálculo de \textit{weakest precondition} formulado por Dijkstra para obtener una obligación de prueba similar a la de \ref{eq:terna-de-hoare} que luego delega a un probador automático de teoremas para completar la verificación.
    Aunque el procedimiento concreto para la construcción de la obligación de prueba en Dafny conlleva una serie de extensiones a las ideas de Dijkstra (que cubriremos oportunamente en el capítulo \ref{ch:pipeline-dafny}), sus definiciones originales para obtener la $wp.S.Q$ en un lenguaje imperativo minimal que llamó ``guarded-commands''\cite{EWD:EWD418}, por un lado son la base para la construcción de la obligación de prueba en Dafny, y por otro reúnen todos los conceptos teóricos que debemos tener en cuenta a la hora de escribir programas anotados en Dafny y lograr su verificación automática.

    A continuación describimos una versión alternativa\footnote{El lenguaje de Dijkstra incluye la posibilidad de tener múltiples guardas para los comandos alternativa y repetición, cada una asociada con un programa que se ejecuta si la guarda es seleccionada, lo cual hace que la ejecución de estos comandos sea no determinística en la teoría, y que la definición de su $wp$, aunque un poco más compleja que la que veremos aquí, resulte muy útil para derivar programas a partir de ella.} del lenguaje ``guarded-commands'' compuesta por los siguientes comandos:
    \begin{itemize}
        \item El comando $skip$ que no realiza modificación alguna en el estado.
        \item La asignación: $x := E$ que asigna para la variable $x$ el valor de la expresión $E$ evaluada en el estado actual.
        \item La concatenación: $S;T$ que ejecuta el programa $S$ y a continuación el programa $T$.
        \item La alternativa: $if\ B\ then\ S\ else\ T$ donde $B$ es una expresión booleana llamada guarda y $S$ y $T$ son programas. Al ejecutarse la alternativa, se evalúa $B$, si evalúa a $True$ se ejecuta $S$, de lo contrario se ejecuta $T$.
        \item Y la repetición: $while\ B\ then\ S$ donde de nuevo $B$ es una guarda y $S$ un programa. En la repetición mientras $B$ evalúe a $True$ se ejecuta su $S$ y se repite el proceso. Si desde el inicio no $B$ evalúa a $False$ el comando equivale a $skip$.
    \end{itemize}

    Además de la descripción mecánica anterior, podemos definir para cada comando $C$ su semántica en términos del transformar de predicados $wp.C$, que para cualquier predicado $Q$ arbitrario devuelve la $wp.C.Q$.

    Para el comando $skip$ tenemos que $wp.skip.Q \equiv Q$, es decir si queremos que $Q$ valga luego de ejecutar un comando que no hace nada, pues necesitamos que $Q$ valga antes de ejecutarlo también.

    En el caso de la asignación tenemos $wp.(x:=E).Q \equiv Q[x:=E]$ donde $Q[x:=E]$ es el resultado de la sustitución sintáctica en $Q$ de todas las ocurrencias de $x$ por $E$. Es decir si queremos que $Q$ valga luego de ejecutar la asignación $x:=E$, entonces $Q$ debía valer antes de ejecutar la asignación (llamemos a este estado $P$) salvo por el hecho de que, si hay cláusulas con referencias a $x$ en $Q$, en $P$ debían valer pero no para $x$ sino para $E$.

    Para la concatenación $S;T$ tenemos $wp.S;T.Q \equiv wp.S.(wp.T.Q)$, que debe ilustrarnos la naturaleza compositiva de la $wp.S.Q$ para cualquier programa $S$ a partir de los comandos que lo conforman.

    En cuanto a la alternativa, tenemos
    \begin{align*}
        wp.(if\ B\ then\ S\ else\ T).Q \equiv (B \Rightarrow wp.S.Q) \land (\lnot B \Rightarrow wp.T.Q)
    \end{align*}
    De lo cual se desprende el siguiente teorema análogo al ``teorema 1'' en el trabajo de Dijkstra:
    \begin{align*}
        &(P \land B \Rightarrow wp.S.Q) \land (P \land \lnot B \Rightarrow wp.T.Q) \\
        &\Rightarrow \\
        &(P \Rightarrow wp.(if\ B\ then\ S\ else\ T).Q)
    \end{align*}
    Pensando ya en la práctica de verificar problemas con Dafny este teorema nos dice que, cuando estemos frente a una alternativa y queramos que el verificador pueda asegurar cierta condición $Q$ luego de la misma, debemos tener en cuenta que el verificador buscará probar por un lado, que lo que sabe hasta el momento en conjunción con $B$ implica la $wp.S.Q$ y por el otro, que lo que sabe hasta el momento en conjunción con $\lnot B$ implica la $wp.T.Q$. Es decir, cuando estemos frente a una alternativa, podemos averiguar si el verificador está logrando asegurar una condición $Q$ en cada caso por separado.

    La definición de Dijkstra para la $wp$ de la repetición no resultaba ser una fórmula de primer orden, por lo cual el cálculo quedaba incompleto.\footnote{Una explicación de esto puede encontrarse en el Capítulo 10 de la historia de la lógica de Hoare publicada por Krzysztof R. Apt \cite{10.1007/s00165-019-00501-3}}.

    Si hago un intento propio de definir la $wp$ para la repetición, lo más general que se me ocurre pensar es lo siguiente:

    Existen $R_n$, $R_{n-1}$, ... $R_0$ para algún $n \geqslant 0$, todas ellas fórmulas de primer orden para las cuales:
    \begin{align*}
    \{P\}while\ B\ do\ S\{Q\} \equiv \ & P \Rightarrow R_n \\
                                     & \land R_n \Rightarrow (B \land wp.S.R_{n-1}) \\
                                     & \land R_{n-1} \Rightarrow (B \land wp.S.R_{n-2}) \\
                                     & \land ... \land \\
                                     & \land R_1 \Rightarrow (B \land wp.S.R_0) \\
                                     & \land R_0 \Rightarrow (\lnot B \land Q)
    \end{align*}

    Es decir, pensando en un ciclo varias iteraciones, para que el ciclo nos lleve de un estado que satisface $P$ a un estado que satisface $Q$ debe haber una primera condición $R_n$ impuesta por $P$, que alcance para que $S$ nos asegure una segunda condición $R_{n-1}$ (y además $B$ por que estamos pensando en un ciclo con varias iteraciones) y así sucesivamente, hasta llegar al punto en que la última ejecución de $S$ nos asegura un estado en donde se satisface una condición $R_0$ que implica que la guarda no ahora no vale y además vale $Q$.

    Pero estamos hablando aquí de la existencia de fórmulas, y no de valores, por tanto estamos abandonando la lógica de primer orden, tal como sucedía, aunque de manera menos explícita, con la definición de $wp$ de Dijkstra.

    Este problema se resuelve típicamente introduciendo los conceptos de invariante y función de cota como parámetros de entrada del cálculo. El invariante es una condición que se cumple a la entrada y salida del ciclo y durante cada una de las iteraciones. La función de cota es la que nos asegura que el ciclo terminará eventualmente. En vez de exigirle al cálculo que resuelva la existencia de las fórmulas $R_n$... $R_0$, le ofreceremos una fórmula para el invariante $I$ y una expresión aritmética para la cota $E_t$ a partir de las cuales se podrían construir $R_n$...$R_0$. Por ejemplo de la siguiente manera:
    \begin{align*}
        & R_n \equiv I \land t \leqslant E_t \\ 
        & R_i \equiv  I \land t \leqslant (E_t - (n - i)) \ \ \ \forall i : 0 \leqslant i < n
    \end{align*}

    Por suerte, no será necesario representar cada una de ellas en la fórmula final que, como veremos a continuación, tendrá un tamaño independiente de $n$.

    Aplicamos algunas modificaciones a \textit{wp} para obtener un cálculo completo que aquí llamaremos \textit{wpi}.
    Reemplazamos nuestro comando repetición por el siguiente: $while\ B\ \{I\}\{E_t\}\ do\ S$, es decir, una versión anotada que nos asegurará que cada ciclo lleva consigo una fórmula para el invariante $I$ y una expresión aritmética para la cota $E_t$. Definimos $wpi.C.Q \equiv wp.C.Q$ para todo comando $C$ distinto de la repetición, y para la repetición de la siguiente manera:

    \begin{align*}
        wpi.(while\ B\ \{I\}\{E_t\}\ do\ S).Q \equiv\ & I \land (I \land B) \Rightarrow wp.S.I \\
            & \land (I \land B) \Rightarrow E_t \geqslant 0 \\
            & \land (I \land B) \Rightarrow wpi.(t := E_t; S)(E_t \leqslant t-1) \\
            & \land (I \land \lnot B) \Rightarrow Q
    \end{align*}
    Donde $t$ es una variable que no aparece en $S$.
    Podemos establecer ahora:
    \begin{align*}
        (P \Rightarrow wpi.(while\ B\ \{I\}\{E_t\}\ do\ S).Q) \Rightarrow \{P\}\ while\ B\ do\ S\ \{Q\}
    \end{align*}

    Notar que utilizamos $\Rightarrow$ en vez de $\equiv$ aquí, ya que el ciclo podría perfectamente satisfacer la especificación sin estar bien anotado. Por eso mismo obviamos el invariante y la función de cota en el término de la derecha. Escribimos entonces:

    \begin{equation}
        \label{eq:wpi-implies-hoare-triple}
        (P \Rightarrow wpi.S.Q) \Rightarrow \{P\}S\{Q\}
    \end{equation}

    Lo cual es suficiente y nos brinda un cálculo completo para intentar probar correctitud de programas imperativos anotados.

    Una prueba de \eqref{eq:wpi-implies-hoare-triple} se adjunta en el Anexo I.

    \section{Referencias que quiero usar}


    ``My presentation of this calculus should, however, not be interpreted as my suggestion that all programs should be developed in this way: it just gives us another handle.'' -- Edsger Dijkstra \cite{EWD:EWD418}

    En \cite{10.1007/BFb0055136} hace una crítica exhaustiva de las definiciones de Dijkstra en A discipline of programming. Lo buscaba en particular, luego de ver el pensamiento circular en la definición de Dijkstra respecto a la wdec. Hay algo de eso expresado por Harrison, aunque en discipline of programming, EDW introduce la weakest liberal precondition (wlp), con lo cual debería revisar primero cómo adaptó la definición tras incluir la wlp.

    ``Therefore, Boogie includes a
    framework for abstract interpretation [CC77], which can infer loop invariants of
    the BoogiePL program. These inferred invariants are inserted as assume state-
    ments into the loop heads of the BoogiePL program, so that they can be assumed
    by the VC to hold at the start of each loop iteration.''\cite{10.1007/11804192_17}
    Lo dejo por acá por que me parece interesante como la inferencia automática de invariantes da lugar en el stack de Dafny para esta rama de investigación en formalización de programas llamada "abstract interpretation". 

    `` Consequently, only for a small number of
    application areas, where programs are very small or where the cost of a soft-
    ware error could be devastating, does full functional program verification stand
    a chance of being cost effective''-- Rustan Leino en \cite{Leino2001} Me trajo a la mente la posibilidad de citar este tipo de frases de los investigadores desde Dijkstra a esta parte para evidenciar cómo evolucionó el ecosistema de herramientas de verificación automática.

    ``We have used a variation of Dijkstra’s guarded commands [10] as our interme-
    diate language''-- Rustan Leino en \cite{Leino2001} La conexión Dijkstra - Leino (Que es al final la conexión Dijkstra - Boogie - Dafny)


    ``One of the barriers to entry for extended static checking is that a regrettably
    large number of programmers don’t really understand preconditions and invari-
    ants. When these concepts are taught in computer science curriculums, students
    tend to practice them only on paper. There’s a large difference between turning
    in a homework assignment that is returned graded a week later and getting in-
    stant feedback from a mechanical checker. It seems to me that the current state
    of the art in extended static checkers, although designed to support program-
    ming in the large, would be quite instructional to use along with the compiler
    and type checker in early (and more advanced) programming classes. Even if the
    students wouldn’t continue using an extended static checker outside the classes,
    the experience of using one with their programming assignments may teach them
    to think in terms of preconditions and invariants, which is likely to breed a new,
    better generation of programmers.'' -- Rustan Leino en \cite{Leino2001}. Choque esos cinco Rustan.

    \section{Alimentando pipeline de verificación de Dafny}

    El camino de investigación y desarrollo que culmina con Dafny como herramienta de verificación de software se expande desde las primeros experimentos en ``Extended Static Checkers (ESC)'' desarrollados para el lenguaje Módula-3 (ESC/Modula-3) y Java (ESC/Java) durante la década del noventa hasta la actualidad. Los ESC buscaban ampliar la capacidad de chequeo estático a un conjunto de errores más amplio que el capturado por el chequeo estático de tipos y que, hasta entonces, solo podían ser detectados en tiempo de ejecución: intentos de acceder a atributos en una variable nula, índices fuera de rango, división por cero, errores de casteo de tipos, etc.\cite{Leino2001}.

    Estas piezas de software, que tenían el objetivo de mejorar la detección temprana de errores en proyectos de desarrollo reales, se volcaron rápidamente al objetivo de la verificación automática de software. Es decir, ya no solo aspiraban a encontrar algunos tipos de errores específicos en los programas, sino a garantizar, cuando esto sea posible, que un programa sea correcto respecto de su especificación.

    La estrategia de verificación elegida fue la construcción de obligaciones de prueba (VCs por las siglas en inglés de \textit{verification conditions}), siendo estas fórmulas en lógica de primer orden construidas de forma tal que resulten válidas sí y solo sí el programa es correcto respecto de su especificación y luego son sometidas a un probador automático de teoremas.

    Para la construcción de las VCs tomaron como base la semántica de programas imperativos presentada primero por Floyd-Hoare y luego llevada al cálculo de \textit{weakest preconditions} por Dijkstra, el cual es enseñado en la materia Algoritmos y Estructuras de Datos I.

    Si bien la puesta en práctica de estas ideas a fin de lograr la verificación automática de software supuso extensiones sobre el lenguaje original propuesto por Dijkstra y su semántica, así como el desarrollo de nuevas estrategias para derivar VCs que los probadores de teoremas puedan procesar de forma eficiente, la conceptualización semántica de la programación imperativa descrita por Dijkstra reúne todos los elementos necesarios a tener en cuenta para desarrollar programas en Dafny


    definir formalmente la semántica de los lenguajes de programación sobre los cuales operaban y . Esta formalización se realizó traduciendo los lenguajes a una extensión  

    \section{Suma del segmento de suma máxima con índices}
    En este problema, el objetivo es averiguar la sumatoria de los elementos del segmento contiguo de suma máxima en un arreglo de números enteros.
    Como el arreglo puede contener números negativos, la solución no siempre es el segmento equivalente al total del arreglo.

    Identificaremos un segmento con dos índices $p$ y $q$, donde $p$ es el índice del primer elemento del segmento y $q-1$ el del último elemento. Diremos que el segmento termina en $A[q-1]$.

    El segmento vacío denotado por dos índices idénticos cualquiera (ejemplo: $i,i$) tiene suma 0.

    Formalmente podemos especificar nuestro programa en Dafny de la siguiente manera:

    \begin{dafny}
    method segmento_de_suma_maxima(A: seq<int>)
        returns (p: nat, q: nat, r: int)
        ensures 0 <= p <= q <= |A|
        ensures r == suma(p, q, A)
        ensures forall i, j :: 0 <= i <= j <= |A| ==> suma(i, j, A) <= r
    {
    }
    \end{dafny}

    Donde \inlinedafny{suma} la definimos como una función recursiva

    \begin{dafny}
    function suma(p:int, q:int, A: seq<int>): int
        requires 0 <= p <= q <= |A|
    {
        if q >= p then 0 else A[p] + suma(p+1, q, A)
    }
    \end{dafny}

    Este problema fue resuelto por Joseph Kadane con un algoritmo de $\mathcal{O}(N)$ el cuál derivaremos a continuación.

    Supongamos que iteramos sobre los elementos del arreglo con la variable $n$. Nos detengamos en alguna iteración arbitraria $n$.

    En esta iteración descubrimos el valor del elemento $A[n]$. Pueden pasar dos cosas:
    \begin{itemize}
        \item O bien, el elemento nos sirve para formar un nuevo segmento de suma máxima, pues incluirlo resulta en un segmento con sumatoria mayor a la conocida hasta ahora.
        \item O bien, no nos sirve, y entonces el segmento de suma máxima es el que ya conocíamos en la iteración anterior.
    \end{itemize}

    En el primer caso el segmento resultante se obtiene agregando $A[n]$ al segmento de suma máxima que pueda haberse logrado terminando en $A[n-1]$, siendo tal vez este el segmento vacío: ($n,n$).

    Supongamos que en cada iteración contamos invariantemente con los valores:
    \begin{itemize}
        \item $u_p$: para denotar el primer índice del segmento de suma máxima terminado en $A[n - 1]$ (o el segmento vacío $n,n$).
        \item $u$: para denotar la suma de dicho segmento.
        \item $p$ y $q$: para denotar los índices del segmento de suma máxima conocido hasta la iteración anterior.
        \item $r$: para denotar la suma de dicho segmento.
    \end{itemize}

    Entonces en el primer caso debemos actualizar $r$ con $u$ + $A[n]$, $p$ con $u_p$ y $q$ con $n+1$. Mientras que en el segundo $r$, $p$ y $q$ no se modifican. Es decir, tendremos en el cuerpo del loop:
    \begin{dafny}
        if u + A[n] > r {
            r := u + A[n];
            p := u_p;
            q := n + 1;
        }
    \end{dafny}

    Para mantener el invariante respecto de $u$ y $u_p$ observemos los siguientes dos casos:
    \begin{itemize}
        \item Sumar $A[n]$ a $u$ resulta en un valor positivo: la suma del segmento terminado en $A[n]$ de suma máxima será $u$ + $A[n]$, y sus índice inicial continuará siendo $u_p$.
        \item Sumar $A[n]$ a $u$ resulta en un valor negativo: entonces el segmento logrado hasta incluso $A[n]$ de suma máxima será en verdad el segmento vacío ($n+1,n+1$ de suma $0$). Lo que se traduce en actualizar $u_p$ con $n+1$ y $u$ con 0.
    \end{itemize}

    - Citar la implementación de wuhan. El problema de especificación.
    - La solución de ir llevando los índices en el invariante.
    - Explicar qué son las funciones, para qué sirven. Pensando en que sea un aporte consumible por estudiantes de la materia.

    Por lo cuál postulamos la siguiente actualización condicional de $u$ y $u_p$ para el cuerpo del loop:
    \begin{dafny}
        if u + A[n] > 0 {
            u := u + A[n];
        } else {
            u_p := n + 1;
            u := 0;
        }
    \end{dafny}

    Con todo el programa, el programa completo con la guarda del loop, función de cota invariantes, e inicialización será:

    \dafnyfile{"Implementación verificada de segmento de suma máxima"}{ejemplos/calculo_de_programas/segmento_de_suma_maxima_con_indices.dfy}

    Dafny logra verificar automáticamente esta implementación.
    (... Sobre la division entera y en cuanto al enfoque intuicion -> matematica)
    Este desarrollo alternativo, pone foco en presentar al lector una estrategia de resolución iterativa del problema, acudiendo a la experiencia común entre las personas de ``pasar cosas'' de un lugar a otro, y cómo esa estrategia puede traducirse en un programa concreto.
    La esperanza, es que al finalizar la explicación, el lector esté en mejores condiciones de identificar otros problemas que puedan resolverse programando ciclos, y la importancia que el invariante adquiere como sostén de la estrategia iterativa de resolución.

    \section{Vieja Introducción}
    En el libro Cálculo de Programas (en adelante simplemente ``el libro''), se busca introducir al estudiante en la construcción de programas imperativos a través de un método formal para derivar el programa a partir de su especificación. La misma debe estar definida por una precondición y una postcondición, ambas escritas como fórmulas del cálculo de predicados estudiado en la materia pre correlativa ``Introducción a los Algoritmos''. El método consiste en tender puentes entre los bloques constructivos de un lenguaje imperativo (\textit{if}, \textit{for}, asignación, \textit{skip}, etc) y el cálculo de predicados. De manera tal que uno pueda plantear el esqueleto de un programa de manera creativa, y concluir los detalles razonando - o calculando - sobre el terreno ya conocido del cálculo de predicados.

    \section{Corrección del teorema de invarianza del libro}
    En cálculo de programas el teorema de invarianza está mal expresado. Confunde alguna precondición válida $P$ del ciclo respecto a una poscondición $Q$ con el invariante.
    La versión corregida sería la siguiente.

    \vspace{1em}

    \noindent\textbf{Teorema de invarianza}

    \noindent Sean $I$, $B$, $Q$ y $S$ tales que:
    \begin{align*}
        \{I \land B\} S \{I\} \land ((I \land \lnot B) \Rightarrow Q)
    \end{align*}
    Para los cuales existe una función $t: Estados \to Int$ tal que
    \begin{align*}
        & (i) I \land B \Rightarrow t \geqslant 0 \\
        & (ii) \{I \land B \land t=T\} S \{t < T\}
    \end{align*}
    Entonces:
    \begin{align*}
        (P \Rightarrow I) \Rightarrow \{P\}while\ B\ do\ S\{Q\}
    \end{align*}

    Este teorema nos habla por un lado de una fórmula hipotética $I$, que llamamos invariante de ciclo y que cumple con las siguientes propiedades: 1) Siempre que ejecutamos el cuerpo del ciclo a partir de un estado que satisface el invariante en conjunción con la guarda llegamos a un estado que satisface el invariante. 2) El invariante en conjunción con la negación de la guarda implican la poscondición $Q$.

    Y por otro lado, nos habla de la existencia de una función $t$, que llamamos función de cota, la cual asegure que el ciclo eventualmente terminará de ejecutarse. Definido así a partir de $(i)$, que acota la función por lo bajo, y $(ii)$ que asegura su decrecimiento en cada paso.

    Contando con un invariante y la existencia de una función de cota que reúnan tales condiciones, el teorema nos dice que: si la precondición $P$ alcanza para establecer el invariante (esto es, $P \Rightarrow I$) entonces cada vez que ejecutemos el ciclo a partir de un estado que satisface la precondición $P$, llegaremos a un estado que satisface la poscondición $Q$ (esto es, $\{P\}while\ B\ do\ S\{Q\}$).
    En mi opinión el libro tiene algunas características que merecen revisión:
    \begin{itemize}
    \item Utiliza, de manera casi exclusiva, un lenguaje formal que privilegia la especificidad, pero sacrifica legibilidad y facilidad de interpretación.
    \item En ocasiones pasa por alto el origen de las estrategias creativas necesarias para construir programas, introduciendo ``esqueletos'' de programas sin mucho preámbulo, y restringiendo el foco de atención a la derivación de las sentencias que constituyen el resto del programa y sí pueden derivarse mediante el método formal.
    \item Los programas obtenidos y sus pruebas, no están escritos en computadora, y por tanto no pueden ser ejecutados ni verificados de forma automática.
    \end{itemize}

    Nuestra hipótesis, es que resultaría más provechoso para el proceso de aprendizaje, primero, introducir la programación imperativa con ejemplos en un lenguaje no formal. Luego, con el lector y su intuición a bordo, identificar en los ejemplos la utilidad de los conceptos básicos (transformación de estado, precondición, poscondición, invariante, etc) y finalmente proceder a la formalización de los mismos para luego poder probar (formalmente), la corrección de los programas obtenidos y resolver problemas más complejos asistidos por una metodología similar a la del libro pero adaptada al uso de Dafny, un lenguaje de programación con soporte para la declaración de especificaciones, pruebas y un entorno de desarrollo capaz de verificar los programas de manera automática.

    A lo largo de este trabajo desarrollamos esta estrategia alternativa.
    % TODO: Revisar más adelante qué texto resume mejor cada capítulo.%
    [WIP]
    En el capítulo 2 presentamos ejemplos de problemas simples que pueden resolverse con programación imperativa. Apelamos a la intuición y la creatividad para construir los programas e identificamos en ellos los conceptos fundamentales.
    En el capítulo 3 los formalizamos (...)
    En el capítulo 4 realizamos pruebas formales de correctitud utilizando Dafny. (...)[END-WIP]

    \bibliography{References}
    \bibliographystyle{plain}
\end{document}
