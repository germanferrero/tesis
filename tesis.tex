\documentclass[12pt, a4paper, openany, fleqn]{book}
\usepackage{amsmath, amssymb,}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{relsize}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{xcolor}
\usepackage{dafny}
\usepackage{spverbatim}
\usepackage{tikz}
\newcommand{\disgrecion}[1]{#1}
\newcommand{\declConst}[2]{\text{const } #1 : #2}
\newcommand{\declVar}[2]{\text{var } #1 : #2}
\renewcommand{\lstlistingname}{Dafny}
\linespread{1.1}
\author{Germán Ferrero}
\title{Construcción formal de programas asistida por Dafny}
\begin{document}
    \chapter{Introducción}
    En el libro Cálculo de Programas (en adelante simplemente ``el libro''), se busca introducir al estudiante en la construcción de programas imperativos a través de un método formal para derivar el programa a partir de su especificación. La misma debe estar definida por una precondición y una postcondición, ambas escritas como fórmulas del cálculo de predicados estudiado en la materia pre correlativa ``Introducción a los Algoritmos''. El método consiste en tender puentes entre los bloques constructivos de un lenguaje imperativo (\textit{if}, \textit{for}, asignación, \textit{skip}, etc) y el cálculo de predicados. De manera tal que uno pueda plantear el esqueleto de un programa de manera creativa, y concluir los detalles razonando - o calculando - sobre el terreno ya conocido del cálculo de predicados.

    En mi opinión el libro tiene algunas características que merecen revisión:
    \begin{itemize}
    \item Utiliza, de manera casi exclusiva, un lenguaje formal que privilegia la especificidad, pero sacrifica legibilidad y facilidad de interpretación.
    \item En ocasiones pasa por alto el origen de las estrategias creativas necesarias para construir programas, introduciendo ``esqueletos'' de programas sin mucho preámbulo, y restringiendo el foco de atención a la derivación de las sentencias que constituyen el resto del programa y sí pueden derivarse mediante el método formal.
    \item Los programas obtenidos y sus pruebas, no están escritos en computadora, y por tanto no pueden ser ejecutados ni verificados de forma automática.
    \end{itemize}

    Nuestra hipótesis, es que resultaría más provechoso para el proceso de aprendizaje, primero, introducir la programación imperativa con ejemplos en un lenguaje no formal. Luego, con el lector y su intuición a bordo, identificar en los ejemplos la utilidad de los conceptos básicos (transformación de estado, precondición, postcondición, invariante, etc) y finalmente proceder a la formalización de los mismos para luego poder probar (formalmente), la corrección de los programas obtenidos y resolver problemas más complejos asistidos por una metodología similar a la del libro pero adaptada al uso de Dafny, un lenguaje de programación con soporte para la declaración de especificaciones, pruebas y un entorno de desarrollo capaz de verificar los programas de manera automática.

    A lo largo de este trabajo desarrollamos esta estrategia alternativa.
    % TODO: Revisar más adelante qué texto resume mejor cada capítulo.%
    [WIP]
    En el capítulo 2 presentamos ejemplos de problemas simples que pueden resolverse con programación imperativa. Apelamos a la intuición y la creatividad para construir los programas e identificamos en ellos los conceptos fundamentales.
    En el capítulo 3 los formalizamos (...)
    En el capítulo 4 realizamos pruebas formales de correctitud utilizando Dafny. (...)[END-WIP]

    \chapter{Introducción a la programación imperativa en Dafny}
    [WIP](...)

    \section{Superar un número entero}
    \subsubsection*{La especificación de un programa}

    Queremos obtener un programa que dado un número entero cualquiera nos devuelva otro mayor. Este simple programa, que finalmente resultará en una línea de código similar a esta:
    \begin{verbatim}
        y = x + 1  # Pseudocódigo
    \end{verbatim}
    nos servirá para razonar acerca de qué es un programa imperativo y cómo podemos garantizar su correctitud.

    En primer lugar, necesitamos ``recibir'' o ``leer'' de alguna forma el número en cuestión, para conocer su valor, y luego poder ``devolver'' o ``escribir'' de alguna forma otro valor mayor, una vez que lo calculemos.
    En la programación imperativa el mecanismo que utilizaremos para satisfacer ambas necesidades es el de \textit{transformación de estado}.
    Un \textit{estado} será una colección de nombres de variables y constantes, con sus respectivos valores, a los que el programa tendrá acceso. Cada una de ellas tendrá un tipo asociado (número entero, booleano, cadena de texto, etc). Al \textit{ejecutar} un programa lo que estaremos haciendo es transformar potencialmente ese estado modificando el valor de sus variables.

    En este caso podemos pensar en un programa $S$ que se ejecutará a partir de un estado con una constante $x$ de tipo entero, que aloja el valor de la cantidad a superar y una variable $y$ del mismo tipo donde depositaremos el resultado.

    Ahora bien, ¿Qué podemos asumir de $x$ e $y$ antes de ejecutar el programa? ¿Qué relación esperamos se cumpla entre $x$ e $y$ luego de la ejecución? Respondernos estas preguntas dará resultado a la \textit{especificación} del programa.

    De la descripción informal que enunciamos inicialmente, no se desprende ninguna relación particular entre $x$ e $y$ que deba valer al inicio de nuestro programa. Es decir, no hay una precondición en particular.

    Al finalizar el programa, queremos que en el estado el valor de $y$ sea estrictamente mayor a $x$. Ésta será nuestra postcondición.

    En efecto, nuestro programa será especificado por una \textit{precondición} y una \textit{postcondición}. Juntas, funcionan como contrato entre quien desarrolla el programa y quien lo ejecuta. Quien ejecuta el programa debe asegurar la precondición y puede asumir la postcondición al finalizar la ejecución. Quien lo desarolla puede asumir la precondición y debe asegurar la postcondición.

    Nos resultará útil la siguiente notación formal para especificar programas, que utiliza \textit{fórmulas} para escribir la precondición y la postcondición. En este caso:
    \begin{align*}
        & \declConst{x}{\mathbb{Z}}, \declVar{y}{\mathbb{Z}}\\
        & \{P: True\} \\
        & S \\
        & \{Q: y > x\}\\
    \end{align*}

    Primero declaramos las variables y constantes a las que el programa tendrá acceso. Y luego la Terna de Hoare que toma la forma $\{P\}S\{Q\}$, donde $S$ es el programa y $P$ y $Q$ fórmulas que definen la precondición y postcondición respectivamente. La terna se intrepreta así: 
    \begin{center}
        \textit{Cada vez que ejecutemos $S$ a partir de un estado que satisface $P$ llegaremos a un estado que satisface $Q$.}
    \end{center}
    

    En nuestro ejemplo $P$ es $True$, lo que simboliza no tener ninguna precondición en particular, puesto que cualquier estado posible satisface $True$. Y $Q$ es $y > x$.

    Hasta aquí, utilizando los conceptos de estado, fórmulas, y transformación de estado, hemos logrado especificar acabadamente qué debe hacer nuestro programa, aún sin hablar en absoluto de cómo lo hará.

    \subsubsection*{La especificación de un programa en Dafny}

    A lo largo de este trabajo, escribiremos programas formalmente especificados, y verificaremos a través de \textit{pruebas} que sus implementaciones sean correctas, eso es, verificar que efectivamente vale $\{P\}S\{Q\}$.

    Para ayudarnos en esta tarea, utilizaremos Dafny, un lenguaje de programación con soporte para declarar especificaciones, y dotado de un entorno de desarrollo capaz de verificar los programas de manera automática.

    Si bien para programas sencillos, como el de superar un número entero, la correctitud del programa será evidente con solo inspeccionarlo y para otros realizar las pruebas manualmente no será un gran desafío, a medida que construyamos programas más complejos descubriremos la practicidad de poder contar con un verificador automático.

    Escribamos entonces la especificación de nuestro programa en Dafny:

    \dafnyfile{Especificación de "superar un número entero"}{ejemplos/01_superar_especificacion.dfy}

    Hemos utilizado el constructor \inlinedafny{method} de Dafny para especificar nuestro programa. La presencia de $\declConst{x}{\mathbb{Z}}$ en el estado está reflejada por el parámetro \inlinedafny{x:int}, los parámetros de los métodos en Dafny son inmutables. Mientras que $\declVar{y}{\mathbb{Z}}$ está en el estado por la inclusión de \inlinedafny{y:int} en la cláusula \inlinedafny{returns}.
    La cláusula \inlinedafny{ensures y > x} se utiliza para especificar la postcondición.

    \subsubsection*{La asignación}
    Nuestro programa no tiene una implementación aún. La implementación de un programa imperativo estará dada por una sucesión de sentencias de varios tipos (que iremos introduciendo sucesivamente), y transforman el estado de una manera u otra. El primer tipo de sentencia que estudiaremos es la ``asignación''.

    Una asignación, que escribiremos como $x_1,...,x_n := E_1,...,E_n$, donde el término izquierdo es una sucesión de nombres de variables y el derecho un número igual de expresiones, transforma el estado del programa asignando a las variables del lado izquierdo los valores que resultan de evaluar las expresiones correspondientes del lado derecho en el estado actual.

    Dafny utiliza esta misma sintaxis para la asignación. Las variables que aparecen en el lado izquierdo deben haber sido declaradas previamente con una sentencia de declaración de variables, que toma la forma \inlinedafny{var x;}, o estar listadas entre los parámetros o valores de retorno del método.

    Las expresiones del lado derecho serán expresiones de Dafny válidas de cualquier tipo, pero por el momento nos concentraremos en expresiones aritméticas que combinan números y variables con los operadores aritméticos básicos $+,-,*,/,\%$

    Nos resultará natural utilizar la asignación para completar el cuerpo de nuestro programa:
    \dafnyfile{Implementación correcta de "superar un número entero"}{ejemplos/02_superar.dfy}
    Si corremos:
    \begin{verbatim}
        $ dafny verify ejemplos/02_superar.dfy
    \end{verbatim}
    veremos que Dafny automáticamente verifica la correctitud de este programa. Cómo lo hace? Cómo verifica Dafny que a partir de cualquier estado que satisface $True$, luego de ejecutar la asignación \inlinedafny{y := x + 1} se llega a un estado que satisface la postcondición $y > x$?

    Para entender esto, pensemos primero qué garantía puede darnos la ejecución de la asignación acerca del estado resultante. Por su definición, la asignación solo puede garantizarnos que luego de la ejecución se cumple $y = x + 1$, no más. A su vez, esto resulta suficiente para probar, por aritmética, que $y > x$.

    En cambio, si proponemos la implementación:
    \dafnyfile{Implementación incorrecta de "superar un número entero"}{ejemplos/03_superar_incorrecto.dfy}
    la única garantía provista por la asignación, post ejecución, es $y = x * 2$, que no garantiza $y > x$ para todo estado posible inicial, puesto que para el estado inicial $\sigma:\{y=0,x=0\}$, si bien luego de la ejecución se cumple $y = x * 2 $, no se cumple $y > x$.

    En efecto, si corremos:
    \begin{verbatim}
        $ dafny verify ejemplos/03_superar_incorrecto.dfy
    \end{verbatim}
    Recibiremos como output:
    \begin{spverbatim}
    examples/03_superar_incorrecto.dfy(3,0): Error: a postcondition could not be proved on this return path
    \end{spverbatim}

    \subsubsection*{Precondición más débil y obligaciones de prueba}
    Notemos que la asignación nos exige una precondición mínima, a partir de la cual, podemos asegurar una postcondición $Q$ luego de ejecutar la asignación. En el primer caso era $True$, pues la asignación por si sola aseguraba la postcondición. En el segundo caso esta es $x > 0$ pues de lo contrario no puede asegurarse la postcondición.
    Llamaremos a esta precondición, la \textit{precondición más débil} de la asignación respecto de $Q$ y la denotaremos $wp.(x := E).Q$ (por \textit{weakest precondition} en inglés).

    El primer paso que deber realizarse para intentar la verificación automática es calcular la $wp.(x := E).Q$.
    Esta puede obtenerse mecánicamente mediante la sustitución sintáctica en $Q$ de todas las ocurrencias de $x$ por $E$ (i.e. $Q[x := E]$) gracias a la siguiente proposición.

    \textbf{Proposición}: Weakest Precondition de la asignación
    \footnote{Encerraremos una fórmula entre corchetes [] para indicar que es válida para cualquier estado posible}
    \footnote{La prueba puede encontrarse en el Anexo I}
    \begin{align*}
        [ wp.(x:=E).Q \equiv Q[x:=E] ]
    \end{align*}
    Una interpretación útil de este proposición, es que lo único que podemos esperar de la asignación, es que realice la transformación de estado que le corresponde, el resto de la postcondición tiene que poder probarse a partir de la precondición.

    En nuestros ejemplos:
    \begin{align*}
        & wp.(y := x + 1).( y > x )\\
        & \equiv \text{\{ Weakest Precondition de la asignación \}}\\
        & x + 1 > x\\
        & \equiv \text{\{ aritmética \}}\\
        & True\\
    \end{align*}

    \begin{align*}
        & wp.(y := x * 2).( y > x )\\
        & \equiv \text{\{ Weakest Precondition de la asignación \}}\\
        & x * 2 > x\\
        & \equiv \text{\{ aritmética \}}\\
        & x > 0\\
    \end{align*}


    El segundo paso es demostrar que la precondición del programa implica la $wp$.
    Siguiendo con los ejemplos, demostrar $True \Rightarrow True$ en un caso y $True \Rightarrow x > 0$ en el otro.
    Llamaremos a estas fórmulas: obligaciones de prueba.

    Sabemos que no existe un método que pueda probar la validez (o refutar) una fórmula dada cualquiera\footnote{En efecto la mayor parte de las teorías son \text{indecidibles}}. Sin embargo existen herramientas, como los SMT Solvers (Satisfiability Modulo Theory Solvers), que pueden intentar o bien probar su validez o bien encontrar un contrajemplo \cite{10.1007/978-3-030-99524-9_23}. Dafny utiliza SMT Solvers para intentar probar las obligaciones de prueba de manera automática. Si lo logra, entonces estamos seguros de la correctitud del programa. Si no lo logra, puede que el programa sea incorrecto (e incluso contemos con un contraejemplo), o bien que Dafny necesite asistencia en la prueba. En tal caso, Dafny nos permite introducir manualmente nuevos lemas y pruebas, que luego el SMT Solver puede aprovechar para verificar nuestro programa.

    \subsection{Concatenación}
    La concatenación es la construcción del lenguaje imperativo que nos permite componer un programa a partir de dos sentencias $S$ y $T$, que se ejecutarán una atrás de la otra.
    Escibimos $S;T$ para denotar el programa que ejecuta primero la sentencia $S$ y luego la sentencia $T$.
    Ejemplo:

    \chapter{El pipeline de verificación de programas Dafny}

    Dafny se apoya en Boogie (un lenguaje intermedio de verificación o IVL, por sus siglas en inglés), para resolver la verificación automática de programas.
    Boogie, como otros IVL, funciona como una capa de abstracción útil en la cual, por arriba, distintos lenguajes con soporte para especificaciones implementan su traducción a Boogie\footnote{
        Boogie fue escrito originalmente como herramienta intermedia del proyecto Spec\#, una extensión de C\# con soporte para especificaciones. Luego tomó vida propia y hoy es utilizado para construir verificadores para otros lenguajes, como el verificador de Dafny para el lenguaje del mismo nombre, o VCC y HAVOC, dos verificadores de C.
    }, y por abajo, Boogie despacha obligaciones de prueba a probadores de teoremas automáticos. En el medio, el IVL, debe encargarse de la generación de esas obligaciones de prueba.

    El pipeline de verificación de programas Dafny se compone entonces, principalmente, por estas tres etapas:
    \begin{itemize}
        \item La traducción del programa Dafny a un programa Boogie.
        \item La generación de obligaciones de prueba a partir del programa Boogie.
        \item La descarga de esas obligaciones de prueba en un SMT Solver, típicamente.
    \end{itemize}

    \section{La traducción de Dafny a Boogie}
    La traducción de Dafny a Boogie no es trivial, la pieza de código que se encarga de ello tiene aproximadamente un millón de líneas escritas en C\#, y codifica cada elemento del lenguaje de Dafny en elementos de Boogie.\footnote{El código fuente para la traducción se encuentra en el \href{https://github.com/dafny-lang/dafny/tree/v4.7.0/Source/DafnyCore/Verifier}{directorio ``Verifier''} del repositorio de Dafny, en donde la clase ``BoogieGenerator'' se construye modularmente a través de múltiples archivos. Dafny además debe encargarse de garantizar trazabilidad entre el código fuente original y los resultados de la verificación obtenidos, a fin de posibilitar un reporte útil de errores.} La expresividad de Boogie posibilita la traducción de lenguajes con múltiples features como Dafny.

    Utilizando la línea de comandos de Dafny podemos obtener la traducción a código Boogie de la siguiente manera
    \begin{verbatim}
        dafny verify my_program.dfy --bprint:my_program.bpl
    \end{verbatim}
    Al hacerlo, nos encontraremos con un programa Boogie mucho más extenso que nuestro programa original en Dafny. Esto es porque la traducción empieza con un preludio\footnote{El código fuente del preludio se encuentra apartado en el \href{https://github.com/dafny-lang/dafny/blob/v4.7.0/Source/DafnyCore/DafnyPrelude.bpl}{directorio ``Prelude''} del repositorio de Dafny}, en el cuál se axiomatizan en Boogie todos los elementos de Dafny, (tipos, expresiones, etc), seguido de la traducción en sí de nuestro programa Dafny.

    \section{La generación de obligaciones de prueba}
    La generación de obligaciones de prueba consiste en una serie de transformaciones del programa Boogie inicial, hacia una versión tal que permita la construcción de una fórmula lógica a partir de las sentencias del programa de forma directa.

    Este pipeline fue descripto por Barnett y Leino\cite{10.1145/1108792.1108813} y se recomienda su lectura para entenderlo en detalle. Aquí haremos un repaso de los conceptos principales que allí se describen.

    \subsection*{ El lenguaje no estructurado de partida}
    El pipeline se basa en programas no estructurados que siguen la siguiente gramática:
    \begin{align*}
        Program \;\;&::=\;\; Block^{+} \\
          Block \;\;&::=\;\; BlockId :\; Stmt;\;\textbf{goto } BlockId^{*} \\
           Stmt \;\;&::=\;\; VarId := Expr\;|\;\textbf{havoc } VarId \\
                &\;\;\;\;\;\;\;\;|\ \textbf{assert } Expr\;|\;\textbf{assume } Expr \\
                &\;\;\;\;\;\;\;\;|\ Stmt ; Stmt \;|\; \textbf{skip} \\
    \end{align*}
    En este pequeño lenguaje un programa está compuesto por uno o más bloques. Al primero de ellos lo denominamos $Start$. Cada bloque está identificado por un $BlockId$, tiene un cuerpo compuesto por una o más sentencias y un conjunto de cero o más bloques \textit{sucesores}. Cuando se ejecuta un bloque se, ejecuta primero su cuerpo, y luego se continúa arbitrariamente con alguno de los bloques sucesores. 

    El operador ``$:=$'' denota la asignación, $\textbf{havoc}$ la asignación de un valor arbitrario a una variable. El operador ``$;$'' se utiliza para componer. Las sentencias $\textbf{assert}$ y $\textbf{assume}$ tienen un rol clave en la generación de obligaciones de prueba y $\textbf{skip}$ es simplemente un atajo para $\textbf{assert True}$.

    La transformación de programas estructurados a esta gramática se logra reemplazando ciclos con $\textbf{goto}$'s y condicionales de la forma:
    \begin{align*}
        \textbf{if}\ (E)\ \{S\}\ \textbf{else}\ \{T\}
    \end{align*}
    con:
    \begin{align*}
        Start:&\;\;\;\textbf{skip};\ \textbf{goto}\ Then,\ Else \\
        Then:&\;\;\;\textbf{assume}\ E;\ S;\ \textbf{goto}\ End \\
        Else:&\;\;\;\textbf{assume}\ \lnot E;\ T;\ \textbf{goto}\ End \\
        End:&\;\;\;...
    \end{align*}
    Las precondiciones pueden codificarse incorporando sentencias $\textbf{assume}$ al principio del bloque $Start$ y las postcondiciones como sentencias $\textbf{assert}$ al final de los bloques sin sucesores.
    Cada programa da lugar a un conjunto de trazas de ejecución posibles empezando desde el bloque $Start$. Un programa es correcto si ninguna de ellas contiene una sentencia $\textbf{assert}$ que evalúe a $False$.

    \subsection*{La eliminación de loops}
    A partir de una versión no estructurada del programa siguiendo esta gramática, los ciclos quedan codificados en la forma:
    \begin{align*}
        LoopHead:\;\;\;&\textbf{assert}\ \text{loop invariant};\\
                       &\textbf{goto}\ Body,\ After \\
        Body:\;\;\;&\textbf{assume}\ \text{loop guard};\\
                   &S;\\
                   &\textbf{goto}\ LoopHead \\
        After:\;\;\;&\textbf{assume}\ \lnot \text{loop guard};\\
                    & ...
    \end{align*}

    A continuación se eliminan los loops, eliminando los ``back edges'' (introducidos por las sentencias de tipo $\textbf{goto}\ LoopHead$). Para esto, primero se mueve la aserción del invariante al bloque predecesor de $LoopHead$, reemplazándolo por sentencias $\textbf{havoc}$ sobre las variables que pueden ser modificadas por el loop, seguido de una sentencias $\textbf{assume}$ para el invariante. De esta forma las trazas que pasen por el bloque $Body$ representan cualquier iteración arbitraria del ciclo y la sentencia $\textbf{goto}\ LoopHead$ puede eliminarse del cuerpo.
    Notar que esta transformación denota una fuerte dependencia en la definición de invariantes para los ciclos que, de no ser provistos por el usuario, se generan automáticamente.

    \subsection*{La pasificación o eliminación de las asignaciones}
    Una vez eliminados los loops, se realiza la ``pasificación'' del programa que consiste en eliminar las asignaciones y en su lugar utilizar sentencias $\textbf{assume}$. Para ello primero se introducen variables auxiliares para cada ``encarnación'' o asignación de las variables del programa, asegurando que en cualquier traza de ejecución posible cada variable sea asignada una única vez, lo que permite a continuación transformar estas asignaciones únicas en sentencias $\textbf{assume}$.

    \subsection*{La construcción de la obligación de prueba}
    Concluídas estas dos transformaciones, se obtiene un programa compuesto por bloques de la forma:
    \begin{verbatim}
        A: S; goto ...
    \end{verbatim} 
    Donde $S$ solo puede ser $\textbf{assume}$, $\textbf{assert}$ o composición de estos dos.\footnote{Las sentencias de tipo $\textbf{havoc }$ pueden eliminarse a los fines generar la obligación de prueba, pues ló único que interesa sobre las variables son sus condicionantes expresados en las sentencias de tipo $\textbf{assume}$ y $\textbf{assert}$. Las sentencias de tipo $\textbf{skip}$, recordemos, son un atajo a $\textbf{assert}\ True$.}
    La Weakest Precondition de cada una de estos tipos de sentencias puede definirse como:
    \begin{align*}
        wp(\textbf{assert}\ P,\;Q)   &= P \land Q \\
        wp(\textbf{assume}\  P,\; Q) &= P \Rightarrow Q \\
        wp(S;T,\;Q)                  &= wp(S,\;wp(T,\;Q)) \\
    \end{align*}
    Para cada bloque A, se define la variable auxiliar $A_{ok}$. Intuitivamente $A_{ok}$ es $true$ si el programa está en un estado a partir del cual todas las ejecuciones que empiecen desde A son correctas. Se postula la ``ecuación de bloque'' para definir $A_{ok}$ formalmente:
    \begin{align*}
        A_{ok} \equiv wp(S, \bigwedge_{B \in Succ(A)} B_{ok})
    \end{align*}
    Donde $Succ(A)$ es el conjunto de bloques sucesores de $A$.

    Por último, siendo $R$ la conjunción de las ecuaciones de esta forma aportadas por cada bloque del programa, la obligación de prueba del programa queda definida como:
    \begin{align}
        R \Rightarrow Start_{ok} \label{eq:VC}
    \end{align}

    Se puede ver, siguiendo los detalles que, si el probador de teoremas resuelve \textit{sat} para la negación de la fórmula \ref{eq:VC}:
    \begin{align*}
        R \land \lnot Start_{ok}
    \end{align*}
    Estamos en situación de que existe un estado a partir del cuál, establecida la semántica del programa ($R$), hay una traza de ejecución incorrecta, es decir que el programa no cumple con su especificación.

    \subsection*{Conclusión}

    La generación de obligaciones de prueba que realiza Boogie, busca crear fórmulas lógicas que sean acotadas en tamaño, y eviten redundancia para facilitar la tarea del probador de teoremas.
  
    Utilizando la línea de comandos de Boogie podemos inspeccionar las distintas versiones del programa obtenidas tras realizar cada una de las etapas del pipeline con la opción \verb|\traceverify|
    \begin{verbatim}
        boogie /traceverify ejemplos/my_program.bpl
    \end{verbatim}

    \section{La delegación de las obligaciones de prueba}
    Las obligaciones de prueba, que resultan del proceso descripto en la sección anterior, deben ser despachadas al probador de teoremas.
    Con la opción \verb|/proverLog| podemos ver el registro de la consulta realizada por Boogie al probador de teoremas, en formato de expresiones SMT-LIB y, como comentarios, las respuestas obtenidas:
    \begin{verbatim}
        boogie /proverLog:my_program.smt my_program.bpl
    \end{verbatim}


    \chapter{Resolución de problemas}
    \section{Suma del segmento de suma máxima}
    En este problema, el objetivo es averiguar la sumatoria de los elementos del segmento contiguo de suma máxima en un arreglo de números enteros.
    Como el arreglo puede contener números negativos, la solución no siempre es el segmento equivalente al total del arreglo.

    Identificaremos un segmento con dos índices $p$ y $q$, donde $p$ es el índice del primer elemento del segmento y $q-1$ el del último elemento.

    El segmento vacío denotado por dos índices idénticos cualquiera (ejemplo: $i,i$) tiene suma 0.

    Formalmente podemos especificar nuestro programa en Dafny de la siguiente manera:

    \begin{dafny}
    method segmento_de_suma_maxima(A: seq<int>)
        returns (p: nat, q: nat, r: int)
        ensures 0 <= p <= q <= |A|
        ensures r == suma(p, q, A)
        ensures forall i, j :: 0 <= i <= j <= |A| ==> suma(i, j, A) <= r
    {
    }
    \end{dafny}

    Donde \inlinedafny{suma} la definimos como una función recursiva

    \begin{dafny}
    function suma(p:int, q:int, A: seq<int>): int
        requires 0 <= p <= q <= |A|
    {
        if q >= p then 0 else A[p] + suma(p+1, q, A)
    }
    \end{dafny}

    Este problema fue resuelto por Joseph Kadane con un algoritmo de $\mathcal{O}(N)$ el cuál derivaremos a continuación.

    Supongamos que iteramos sobre los elementos del arreglo. Nos detengamos en alguna iteración arbitraria $n$.

    En esta iteración descubrimos el valor del elemento $A[n]$. Pueden pasar dos cosas:
    \begin{itemize}
        \item O bien, el elemento nos sirve para formar un nuevo segmento de suma máxima, pues incluirlo resulta en un segmento con sumatoria mayor a la conocida hasta ahora.
        \item O bien, no nos sirve, y entonces el segmento de suma máxima es el que ya conocíamos en la iteración anterior.
    \end{itemize}

    En el primer caso el segmento resultante se obtiene agregando $A[n]$ al segmento de suma máxima que pueda haberse logrado terminando en $A[n]$ (puede ser el segmento vacío).

    Supongamos que en cada iteración contamos invariantemente con los valores:
    \begin{itemize}
        \item $u_p$: para denotar el primer índice del segmento de suma máxima terminado en $A[n - 1]$.
        \item $u$: para denotar la suma de dicho segmento.
        \item $p$ y $q$: para denotar los índices del segmento de suma máxima conocido hasta la iteración anterior.
        \item $r$: para denotar la suma de dicho segmento.
    \end{itemize}

    Entonces en el primer caso debemos actualizar $r$ con $u$ + $A[n]$, $p$ con $u_p$ y $q$ con $n+1$. Mientras que en el segundo $r$, $p$ y $q$ no se modifican. Es decir, tendremos en el cuerpo del loop:
    \begin{dafny}
        if u + A[n] > r {
            r := u + A[n];
            p := u_p;
            q := n + 1;
        }
    \end{dafny}

    Para mantener el invariante respecto de $u$ y $u_p$ observemos los siguientes dos casos:
    \begin{itemize}
        \item Sumar $A[n]$ a $u$ resulta en un valor positivo: la suma del segmento terminado en $A[n]$ de suma máxima será $u$ + $A[n]$, y sus índice inicial continuará siendo $u_p$.
        \item Sumar $A[n]$ a $u$ resulta en un valor negativo: entonces el segmento logrado hasta incluso $A[n]$ de suma máxima será en verdad el segmento vacío (de suma 0) y, a partir de la siguiente iteración, solo tendrá sentido buscar segmento de suma máxima ``terminando en $A[n]$", desde el elemento siguiente: $n + 1$.
    \end{itemize}

    - Citar la implementación de wuhan. El problema de especificación.
    - La solución de ir llevando los índices en el invariante.
    - Explicar qué son las funciones, para qué sirven. Pensando en que sea un aporte consumible por estudiantes de la materia.

    Por lo cuál postulamos la siguiente actualización condicional de $u$ y $u_p$ para el cuerpo del loop:
    \begin{dafny}
        if u + A[n] > 0 {
            u := u + A[n];
        } else {
            u_p := n + 1;
            u := 0;
        }
    \end{dafny}

    Con todo el programa, el programa completo con la guarda del loop, función de cota invariantes, e inicialización será:

    \dafnyfile{"Implementación verificada de segmento de suma máxima"}{ejemplos/calculo_de_programas/segmento_de_suma_maxima.dfy}

    Dafny logra verificar automáticamente esta implementación.

    \chapter{Máximo común divisor}

    Queremos escribir un programa, verificado, que compute el máximo común divisor entre dos números enteros positivos $m$ y $n$,
    con $m >= n$. Formalmente, definimos el máximo común divisor $mcd$ como:

    \begin{center}
        \begin{math}
            mcd \mid m \land mcd \mid n \land (\forall d: d \mid m \land d \mid n :: d \leq mcd)
        \end{math}
    \end{center}

    Mi primera exploración en la búsqueda de un algoritmo que compute el $mcd$, antes de que Internet me recuerde que Euclides propuso uno muy bueno en el 300AC, fue recordar la factorización en primos de $m$ y $n$. Dada por:

    \begin{center}
        \begin{math}
            m = \prod_{i=0}^{i=maxPm} p_{i}^{m_i}\ , \ \ \ n = \prod_{i=0}^{i=maxPm} p_{i}^{m_i}
        \end{math}
    \end{center}

    en donde $p_0=2$, $p_1= 3$, ... y $p_{maxPm}$, $p_{maxPn}$ son los primos más grandes que aparecen en la factorización de $m$ y $n$ respectivamente. Y $m_i$, $n_i$ los exponentes del primo $p_i$ en sus factorizaciones, (siendo $x_i=0$, el caso en que el $p_i$ no aparece en la factorización).

    Y recordar también que $mcd$ será:

    \begin{center}
        \begin{math}
            mcd = \prod_{i=0}^{i=min(maxPm, maxPn)} p_{i}^{min(m_i, n_i)}
        \end{math}
    \end{center}

    Con esto podemos definir la factorización de un número $X$ hasta el primo $k$ como:
    \begin{center}
        \begin{math}
            SubFact(x, k) = \frac{x}{\prod_{i=k+1}^{i=maxPx} p_{i}^{x_i}} 
        \end{math}
    \end{center}

    Con esto, podemos proponer el invariante:
    \begin{center}
        \begin{math}
            I: mcd \mid SubFact(m, i) \land mcd \mid SubFact(n, i) \land (\forall d: d \mid SubFact(m, i) \land d \mid SubFact(n, i) :: d \leq mcd) 
        \end{math}
    \end{center}

    Si se cumple en la iteración $i$, luego podemos mantenerlo para la iteración $i+1$ actualizando $mcd$ con:

    \begin{center}
        \begin{math}
            mcd := mcd * p_{i+1}^{min(m_{i+1}, n_{i+1})}
        \end{math}
    \end{center}

    Para lo cuál necesitamos contar con $p_{i+1}$, $m_{i+1}$ y $n_{i+1}$. Podemos obtener $p_{i+1}$, de forma naive tal vez, iterando sobre los enteros mayores a $p_{i}$, hasta encontrar alguno que no sea divisible por ningún primo entre $p_0$ y $p_{i}$, para lo cual deberíamos contar en cada iteración con la lista completa de primos hasta $p_{i}$. Por su parte, $m_{i+1}$ y $n_{i+1}$ pueden calcularse iterando sobre el exponente de $p_{i+1}$ y frenando cuando el resultado deje de dividir a $m$ y $n$ respectivamente.

    Debieramos avanzar en el loop hasta que $p_i$ sea mayor o igual a $min(\sqrt(m), \sqrt(n))$.

    Hasta aquí pareciera que el loop propuesto funcionaría, aunque la complejidad algorítmica es mayor a la del algoritmo que Euclides propuso hace ya 2324 años.

    \section{El algoritmo de Euclides}
    Hay alguna técnica de obtención de invariantes que me hubiera llevado a la misma realización que tuvo Euclides? Puede el método reemplazar a la creatividad?
    Euclides - sospecho - no llegó a proponer su algoritmo manipulando ecuaciones, sino observando la geometría de líneas con una longitud múltiplo de alguna unidad. De la misma forma en que Pitágoras llegó a su famoso teorema de pitágoras observando triángulos. De nuevo, sospecho.

    Entonces, tenemos que pensar la verificación formal de programas necesariamente como un método para derivar programas? O podemos dejarle ese papel a la creatividad y el ingenio, y utilizar las técnicas de verificación formal para \textbf{probar} que los programas son correctos.

    Probar que el algoritmo de Euclides es correcto, es una tarea tan importante como la demostración de cualquier teorema. En ese sentido no hay diferencia entre un programa y una equivalencia matemática. Ambas cosas pueden obtenerse a partir de un proceso creativo, y necesitan ser demostradas, bajo un proceso metódico, cuidadoso, formal.

    Mi siguiente paso fue entonces entender por qué el procedimiento propuesto por Euclides funciona siempre, es decir, es correcto.


    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Draw the bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            \draw[fill=green!50] (\m*\scale, 0) rectangle (\m*\scale+ \n*\scale, 0.5);% Second bar

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\m*\scale + \n*\scale/2, 0.25) {\textbf{n}};

        \end{tikzpicture}
        \caption{Las varillas de Euclides} \label{varillas_euclides}
    \end{figure}

    Euclides propuso pensar en $m$ y $n$ como dos varillas de largo $m$ unidades y $n$ unidades, siendo la unidad una varilla de, pongamos, 1cm (Figura \ref{varillas_euclides}).
    Y buscar la varilla de largo $d$ más larga que logre componer ambas de manera exacta.

    Que $d$ pueda componer a ambas, es otra forma de decir que $d \mid m$ y $d \mid n$. Que sea la más larga entre las que pueden componerlas quiere decir que $d = mcd(m,n)$.

    Euclides razonó:

    Si la más pequeña puede componer a la más grande ($n \mid m$), entonces ya está: $d=n=mcd(m,n)$, pues cualquier otra varilla que compone a $n$ es necesariamente menor o igual a $n$.

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Top bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            % Bottom bars
            \draw[fill=green!50] (0, 0.5) rectangle (\n*\scale, 1);
            \draw[fill=green!50] (\n*\scale, 0.5) rectangle (2 * \n*\scale, 1);
            \draw[fill=red!50] (2*\n*\scale, 0.5) rectangle (2 * \n*\scale + \scale, 1);

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\n*\scale/2, 0.75) {\textbf{n}};
            \node at (\n*\scale + \n*\scale/2, 0.75) {\textbf{n}};
            \node at (2 * \n*\scale + \scale/2, 0.75) {\textbf{r}};

        \end{tikzpicture}
        \caption{$n$ no logra componer a $m$, y tenemos un resto $r$} \label{varillas_euclides_resto}
    \end{figure}

    Sino, tenemos que $n$ entra alguna cantidad $q$ de veces en $m$ y luego queda un resto $r$ (Figura \ref{varillas_euclides_resto}).

    En este caso, la varilla de largo $d$ que estamos buscando debe componer también a $r$. Veamos por qué. Tenemos por un lado que $d$ compone a $n$ y $d$ compone a $m$. Por otro, $m$ compuesta por una cantidad $q$ de varillas $n$ y un resto $r$.
    Las $q$ varillas de largo $n$ las sabemos compuestas por $d$, por tanto lo que resta ($r$), debe poder componerse con $d$ para que el total $m$ quede compuesto por $d$ a su vez. Si quedara un resto al intentar componer $r$ con $d$, tendríamos que $d$ no compone $m$ (Figura \ref{varillas_euclides_mcd_del_resto}).

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[yscale=-1]
            % Bar lengths (scaled)
            \def\m{9} % Length of the first bar
            \def\n{4} % Length of the second bar
            \def\bd{0.8} % Length of falsy mcd bar
            \def\scale{1cm} % Scaling factor for bar lengths

            % Top bars
            \draw[fill=blue!50] (0, 0) rectangle (\m*\scale, 0.5); % First bar (a)
            % Bottom bars
            \draw[fill=green!50] (0, 0.5) rectangle (\n*\scale, 1);
            \draw[fill=green!50] (\n*\scale, 0.5) rectangle (2 * \n*\scale, 1);
            \draw[fill=red!50] (2*\n*\scale, 0.5) rectangle (2 * \n*\scale + \scale, 1);
            \draw[fill=orange!50] (0, 1) rectangle (\bd, 1.5);
            \draw[fill=orange!50] (\bd, 1) rectangle (2*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 2, 1) rectangle (3*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 3, 1) rectangle (4*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 4, 1) rectangle (5*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 5, 1) rectangle (6*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 6, 1) rectangle (7*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 7, 1) rectangle (8*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 8, 1) rectangle (9*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 9, 1) rectangle (10*\bd, 1.5);
            \draw[fill=orange!50] (\bd * 10, 1) rectangle (11*\bd, 1.5);
            \draw[fill=red!75] (\bd * 11, 1) rectangle (\m*\scale, 1.5);

            \node at (\m*\scale/2, 0.25) {\textbf{m}};
            \node at (\n*\scale/2, 0.75) {\textbf{n}};
            \node at (\n*\scale + \n*\scale/2, 0.75) {\textbf{n}};
            \node at (2 * \n*\scale + \scale/2, 0.75) {\textbf{r}};
            \node at (\bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 1 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 2 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 3 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 4 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 5 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 6 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 7 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 8 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 9 + \bd/2, 1.25) {\textbf{d}};
            \node at (\bd * 10 + \bd/2, 1.25) {\textbf{d}};

        \end{tikzpicture}
        \caption{Si $d$ pudiera componer a $n$ pero no a $r$, tampoco compondría a $m$}
        \label{varillas_euclides_mcd_del_resto}
    \end{figure}

    Sea $r = m \% n$. Tenemos entonces dos casos:
    \begin{itemize}
        \item $r = 0 \land d = n$ ó
        \item $r > 0 \land d \mid r $
    \end{itemize}

    en el segundo, como $d \mid n$ y $d \mid r$, tenemos que $d \leq mcd(n, r)$. Veamos además que $mcd(n,r) \leq d$. Si tomamos $d'=mcd(n,r)$, tendríamos también que $d' \mid m$, pues $m = q * n + r$, por tanto $d' <= d = mcd(n,m)$, con lo cual $d = mcd(n,r)$.

    Es decir que los dos casos son:
    \begin{itemize}
        \item $r = 0 \land d = n$ ó
        \item $r > 0 \land d = mcd(n, r) $
    \end{itemize}

    En el primer caso no queda nada por hacer, en el segundo podemos repetir el razonamiento reemplazando $m$ por $n$ y $n$ por $r$. Y como en cada iteración el resto de la división de $m$ y $n$ siempre será menor al de la iteración anterior y a su vez, por ser resto de una división, está acotado por abajo en $0$, sabemos que en algún momento terminaremos.

    \subsection{Implementación en Dafny}
    Implementar el algoritmo de máximo común divisor de Euclides en Dafny, de manera tal que el verificador de Dafny logre verificar nuestra implementación despierta nuevas preguntas y potenciales respuestas sobre \textbf{qué} conocimiento posee el verificador de Dafny y \textbf{cómo o cuándo} puede aplicarlo.

    Dafny sabe acaso que $mcd(m, n) = mcd(n, m\%n)$? Se lo podemos decir? Si se lo decimos, puede aplicarlo en la verificación?
    Las respuestas rápidas son: ``no lo sabe'', ``se lo podemos decir'', y ``hay que ayudarlo a ubicar el nuevo saber en el formato y lugar correcto''.

    Mi camino hacia lograr la implementación verificada no fue lineal, sino que tuvo una instancia de probar distintas estrategias ``contra la caja negra''. Sin embargo, el desarrollo puede realizarse de manera metodológica y ordenada, siguiendo estos pasos:
    \begin{enumerate}
        \item Especificar el programa.
        \item Testear la especificación.
        \item Definir el invariante y la guarda.
        \item Declarar las variables necesarias.
        \item Especificar inicialización y cuerpo del loop.
        \item Implementar la inicialización y el cuerpo del loop.
    \end{enumerate}

    \footnote{
    Una implementación de este algoritmo utilizando las propiedades de $mcd(m, n) == mcd(m, m - n)$ si $m \ge n$ y simetría puede encontrarse en la serie Dafny Power User de Rustan Leino el sitio web de Rustan Leino bajo el nombre de \href{https://leino.science/papers/krml279.html}{Case study of definitions, proofs, algorithm correctness: GCD utiliza
    }. Leino define la función GCD como el máximo elemento de la intersección de los conjuntos de divisores y luego implementa el algoritmo de Euclides, utilizando esta función para la especificación e incluyendo las pruebas de los lemmas necesarios. Se recomienda su lectura como complemento de esta sección.}

    \subsubsection*{Especificación del programa}
    Definimos para ello un método con su precondición y postcondición:

    \begin{dafny}
predicate es_el_mcd(d: int, m: int, n: int)
{
    0 < d <= n &&
    m % d == 0 &&
    n % d == 0 &&
    forall d' :: 
        (0 < d' <= n && m % d' == 0 && n % d' == 0)
            ==> d' <= d
}

method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
    requires 0 < n <= m
    ensures es_el_mcd(mcd, m, n)
    \end{dafny}

    Tener definido el predicado ``es\_el\_mcd'' nos será útil a continuación para la testear la especificación y definir el invariante.

    \subsubsection*{Testear la especificación}
    Al escribir software verificado, restringimos el espacio para el error humano de la implementación a la definición de la especificación.
    Fácilmente podemos caer en el error de escribir una especificación erronea para el problema que teníamos que resolver, y terminar en escenarios confusos a la hora de verificar la implementación. Puesto que el verificador no puede saber del error que cometimos en la especificación mientras que nosotros nos encontramos interpretando la salida de la verificación asumiendo que la especificación es correcta.
    Afortunadamente en Dafny podemos testear la especificación.
    El verificador es capaz de validar el predicado ``es\_el\_mcd'' para algunos casos concretos con números pequeños que nos ayudan a ganar seguridad sobre la correctitud de la especificación.\footnote{Se recomienda al lector modificar el predicado o los casos de tests para forzar un error de verificación. En particular ver qué sucede si equivocamos $d' < d$ en vez de $d' <= d$ en el predicado}.

    \begin{dafny}
method test_es_el_mcd_numeros_chicos(){
    assert es_el_mcd(1, 8, 3);
    assert !es_el_mcd(2, 8, 3);
    assert es_el_mcd(5, 2345, 5000);
    assert !es_el_mcd(4, 2345, 5000);
    assert es_el_mcd(1, 49163, 9113);
}
    \end{dafny}

    \subsubsection*{Definir el invariante y la guarda}

    Recordemos que la estrategia algorítmica era, sabiendo que $d = mcd(m, n)$, ir seleccionando en cada iteración dos varillas una más larga: $m'$ y otra más corta: $n'$, manteniendo dos afirmaciones:
    \begin{itemize}
        \item $d = mcd(m', n')$ y
        \item sí $n'$ compone a $m'$, entonces $d = n'$.
    \end{itemize}

    Nos será útil definir el invariante como un predicado:

    \begin{dafny}
predicate invariante(d: int, m': int, n': int, r: int) {
    && es_el_mcd(d, m', n')
    && r == m' % n'
    && (r == 0 ==> d == n')
}
    \end{dafny}

    En la estrategia propuesta, seleccionábamos $m'$ y $n'$ de forma tal que $r$ se reduce en cada iteración. Proponemos entonces como guarda del loop $r > 0$. En el paso de especificar inicialización y cuerpo del loop, veremos además que el verificador logra demostrar que el invariante junto con la negación de la guarda implican la postcondición.

    \subsubsection*{Declarar las variables necesarias}
    Hay cuatro variables implicadas en el invariante: $d: int$, $m': int$, $n': int$ y $r: int$.
    Las últimas tres: $m'$, $n'$ y $r$ tomarán valores concretos en la inicialización y serán actualizadas en cada iteración, mientras que para $d$ no conocemos su valor hasta el final. Lo único que sabemos de $d$ es que al iniciar el programa refiere al $mcd$ de $m$ y $n$ (los parámetros de entrada), y luego en cada iteración $d$ es también el $mcd$ de las varillas que estamos analizando. Esto convierte a $d$ en una variable especial, que es necesaria para la verificación pero no se computará en tiempo de ejecución del programa. En Dafny estas variables se llaman \textit{ghost variables} y se definen así:

    \begin{dafny}
ghost var d: int :| p(d);
    \end{dafny}

    que leemos como ``Sea d tal que el predicado p vale para d''. Utilizando una ghost variable podemos referirnos con $d$ al $mcd$ de $m$ y $n$.

    \begin{dafny}
ghost var d: int :| mcd(d, m, n);
    \end{dafny}

    Sumando las demás variables involucradas podemos escribir la declaración de las mismas al inicio de nuestro método:

    \begin{dafny}
method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
    requires 0 < n <= m
    // ensures es_el_mcd(mcd, m, n)
{
    ghost var d: int :| es_el_mcd(d, m, n);
    var m': int, n': int, r: int;
}
    \end{dafny}

    Aquí hemos comentado la postcondición de manera intencional. Comentando la postcondición, podemos averiguar si el verificador encuentra algún problema ``previo'' al incumplimiento de la postcondición teniendo en cuenta las líneas de implementación que hemos escrito hasta el momento.
    En este caso, notamos que Dafny devuelve el error: ``cannot establish the existence of LHS values that satisfy the such-that predicate'' para la línea 5. \footnote{Si no comentábamos la postcondición, el verificador nos hubiera devuelto un error relativo al incumplimiento de la postcondición y solo nos enteraríamos de este problema previo más adelante, al especificar inicialización y cuerpo del loop. Tal vez esta sea una oportunidad de mejora en el reporte de errores del verificador.}
    Nosotros sabemos que para dos números enteros positivos existe un máximo común divisor pero Dafny no lo sabe. Podemos decírselo definiendo un axioma que establezca que el máximo común divisor entre m y n existe e invocándolo justo antes de la definición de $d$. \footnote{Un axioma en Dafny, es un lemma que no conlleva una prueba. Si quitamos :axiom, Dafny nos pedirá que en el cuerpo del lemma escribamos su prueba. Podríamos optar por escribir una demostración del lemma para lo cual nos sería útil la lectura de la nota \href{https://leino.science/papers/krml275.html}{Iterating over a Collection} de la serie ``Dafny Power User'' en donde Rustan Leino muestra cómo probar propiedades básicas sobre colecciones como la existencia de un elemento mínimo.}

    \begin{dafny}
lemma {:axiom} existe_un_mcd(m:int, n:int)
    ensures exists d: int :: es_el_mcd(d, m, n)

method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
    requires 0 < n <= m
    // ensures es_el_mcd(mcd, m, n)
{
    assert exists d: int :: es_el_mcd(d, m, n) by {
        existe_un_mcd(m, n);
    }
    ghost var d: int :| es_el_mcd(d, m, n);
    var m': int, n':int , r: int;
    m', n', r := inicializacion(d, m, n);
}
    \end{dafny}

    Con la introducción del axioma, el error de verificación desaparece. La construcción \textit{assert ... by} aporta claridad sobre el uso del lemma.

    \subsubsection*{Especificar inicialización y cuerpo del loop.}

    Cuando invocamos un método auxiliar desde un método principal, para la verificación de este último Dafny asume que el primero cumple con su especificación y se limita a verificar el método principal bajo esa asunción. Haciendo uso de esta decisión de diseño podemos especificar un método para la inicialización y otro para el cuerpo del loop y validar que hemos elegido correctamente invariante y guarda incluso antes de implementar cada uno de ellos. La especificación de ambos es directa.

    En la inicialización, requerimos como precondición la misma precondición sobre los parámetros de entrada que tiene nuestro programa, sumado a la condición que impusimos sobre la ghost variable $d$, luego pedimos que asegure el invariante de modo que se satisfaga al ingresar al loop.

    En la especificación del cuerpo pedimos que la guarda y el invariante se cumplan antes de la ejecución y aseguramos que luego de ejecutar el invariante se sigue cumpliendo y que la función de cota se redujo.

    \begin{dafny}
method inicializacion(ghost d: int, m: int, n: int)
    returns (m': int, n': int, r: int)
    requires 0 < n <= m
    requires es_el_mcd(d, m, n)
    ensures invariante(d, m', n', r)

method cuerpo(ghost d: int, m: int, n: int, r: int)
    returns (m': int, n': int, r': int)
    requires r > 0
    requires invariante(d, m, n, r)
    ensures invariante(d, m', n', r')
    ensures r' < r
    \end{dafny}

    Ahora podemos utilizar estos métodos  en el método principal para obtener una implementación verificada del mismo y, aunque falta implementar los métodos inicializacion y cuerpo, ya hemos logrado validar el invariante, la guarda, y el valor de retorno que debemos dar a la salida del loop.

    \begin{dafny}
method maximo_comun_divisor(m: int, n: int) returns (mcd: int)
    requires 0 < n <= m
    ensures es_el_mcd(mcd, m, n)
{
    assert exists d: int :: es_el_mcd(d, m, n) by {
        existe_un_mcd(m, n);
    }
    ghost var d: int :| es_el_mcd(d, m, n);
    var m': int, n':int , r: int;
    m', n', r := inicializacion(d, m, n);
    while (r > 0)
        decreases r
        invariant invariante(d, m', n', r)
    {
         m', n', r := cuerpo(d, m', n', r);
    }
    return n';
}
    \end{dafny}

    \subsubsection*{Implementar la inicialización y el cuerpo del loop.}

    Con la siguiente implementación de la inicialización, la verificación sale de forma directa:
    \begin{dafny}
method inicializacion(ghost d: int, m: int, n: int)
    returns (m': int, n': int, r: int)
    requires 0 < n <= m
    requires es_el_mcd(d, m, n)
    ensures invariante(d, m', n', r)
    {
        r := m % n;
        m' := m;
        n' := n;
    }
    \end{dafny}

    En cuanto al cuerpo, el verificador sobrepasa el límite de tiempo permitido antes de lograr verificar la implementación  para la implementación que sabemos válida por la demostración ``en papel'' realizada anteriormente.

    \begin{dafny}
method cuerpo(ghost d: int, m: int, n: int, r: int)
    returns (m': int, n': int, r': int)
    requires r > 0
    requires invariante(d, m, n, r)
    ensures invariante(d, m', n', r')
    ensures r' < r
{
    m' := n;
    n' := r;
    r' := m' % n';
}
    \end{dafny}

    Sucede que Dafny no conoce la propiedad $mcd(m, n) = mcd(n, m\%n)$, que es la clave para poder probar el programa. Si introducimos un axioma que establezca esa propiedad, Dafny efectivamente logra utilizarlo para verificar la implementación del cuerpo.

    \begin{dafny}
lemma {:axiom} mcd_del_modulo(d:int, m:int, n:int)
    requires es_el_mcd(d, m, n)
    requires n > 0
    ensures es_el_mcd(d, n, m % n)

method cuerpo(ghost d: int, m: int, n: int, r: int)
    returns (m': int, n': int, r': int)
    requires r > 0
    requires invariante(d, m, n, r)
    ensures invariante(d, m', n', r')
    ensures r' < r
{
    assert es_el_mcd(d, n, m % n) by {
        mcd_del_modulo(d, m, n);
    }
    m' := n;
    n' := r;
    r' := m' % n';
}
    \end{dafny}

    La versión final verificada del algoritmo de Euclides para el máximo común divisor, con todos los componentes reunidos, será:

    \dafnyfile{Versión final del máximo común divisor en Dafny}{ejemplos/mcd/mcd.dfy}

    \subsubsection*{Nota sobre los lemmas}
    Mi primer intento para los lemmas \textit{existe\_el\_mcd} y \textit{mcd\_del\_modulo} fue declararlos de la siguiente manera:

    \begin{dafny}
lemma {:axiom} existe_el_mcd()
    ensures forall m, n :: 0 < n <= m ==> exists d: int :: es_el_mcd(d, m, n)

lemma {:axiom} mcd_del_modulo()
    ensures forall d, m, n : int :: 0 < d <= n <= m ==> (es_el_mcd(d, m, n) <==> es_el_mcd(d, m, m % n))
    \end{dafny}

    E invocarlos al inicio del método principal, pero Dafny no logra verificar el programa de esta manera. A esto me refería con la pregunta de \textbf{cómo o cuándo} puede aplicar Dafny el conocimiento que le agregamos. Hay que facilitarle a Dafny los lemmas de forma tal que su firma o interfaz pueda ser correspondida con las variables del contexto en donde necesita usarlos para la prueba.

    \chapter{Misc}
    \section{El valor absoluto de un número entero}
    [WIP]: (Introduccion del if)

    \section{La división de números enteros}
    Queremos obtener un programa que dados dos números $x$ e $y$, compute el cociente $q$ y el resto $r$ de la división entera de $x$ por $y$.
    Recordemos que el cociente y el resto cumplen:
    $$x = y * q + r$$
    Ahora bien, ¿cómo podemos computar $q$ y $r$, para cualquier $x$ e $y$ dados?
    Una alternativa razonable es construir iterativamente tanto $q$ como $r$, partiendo de valores iniciales y acercándolos en cada paso a su valor final.
    Si en todo momento, mantenemos la cantidad de $x$ distribuída entre cierta cantidad de $y$’s (esto es $q$) y el resto que falta para llegar a cubrir $x$ (esto es $r$), entonces podemos imaginar un ciclo en el que empezamos con $q$ igual a 0 y todo $x$ está en $r$.
    Luego en cada paso, y mientras podamos extraer una cantidad $y$ de $r$, la sustraemos de ahí y la pasamos a $q$.
    Es decir, empezamos con:
    \begin{verbatim}
        q:=0;
        r:=x;
    \end{verbatim}
    Y en cada paso mientras que $r \geq y$, ejecutamos
    \begin{verbatim}
        q:=q + 1;
        r:=r - y;
    \end{verbatim}

    Y así sucesivamente hasta que $y$ no quepe en $r$ ( $ y > r $ ). Para entonces $q$ y $r$ serán respectivamente el cociente y el resto de la división de $x$ por $y$.

    Nuestro programa final será:
    \begin{verbatim}
    q:=0;
    r:=x;
    do r >=y
        q:=q+1;
        r:=r-y;
    od
    \end{verbatim}
    Notemos en este programa simple, que:
    \begin{itemize}
        \item En todo momento se cumple:
        $$x = q * y + r$$
        Este es nuestro \textit{invariante}, y proviene de nuestra estrategia inicial de tener distribuído $x$, paso a paso, entre $q$ y $r$.
        \item Que debemos continuar iterando mientras que $r >= y$,
        Esta es nuestra \textit{guarda}.
        \item Que si se cumple el invariante y la guarda deja de cumplirse entonces hemos terminado.
        \item Y que a su vez, estamos seguros de que en algún momento la guarda dejará de cumplirse, por que en cada paso reducimos $r$.
    \end{itemize}

    Este desarrollo alternativo, pone foco en presentar al lector una estrategia de resolución iterativa del problema, acudiendo a la experiencia común entre las personas de ``pasar cosas'' de un lugar a otro, y cómo esa estrategia puede traducirse en un programa concreto.
    La esperanza, es que al finalizar la explicación, el lector esté en mejores condiciones de identificar otros problemas que puedan resolverse programando ciclos, y la importancia que el invariante adquiere como sostén de la estrategia iterativa de resolución.
    \chapter{Dafny}
    Continuará.

    \bibliography{References}
    \bibliographystyle{plain}
\end{document}
